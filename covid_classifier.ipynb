{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid Classifier Model\n",
    "### Goals\n",
    "Classify:\n",
    "- Normal CXR\n",
    "- Viral Pneumonia CXR\n",
    "- COVID CXR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directories for Dataset\n",
    "Separate the data to use later as generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentar threshold de Early Stop.\n",
    "# Aumentar las rotaciones y escalas.\n",
    "# Jugar con las metricas AUC y recall.\n",
    "import os\n",
    "\n",
    "BASE_PATH = '/home/hivini/learn/research/new-covid'\n",
    "ORIGINAL_DATASET_DIR = os.path.join(BASE_PATH, 'COVID-19_Radiography_Dataset')\n",
    "ORIGINAL_VIRAL_DIR = os.path.join(ORIGINAL_DATASET_DIR, 'Viral Pneumonia')\n",
    "ORIGINAL_COVID_DIR = os.path.join(ORIGINAL_DATASET_DIR, 'COVID')\n",
    "ORIGINAL_NORMAL_DIR = os.path.join(ORIGINAL_DATASET_DIR, 'Normal')\n",
    "DATASET_DIR = os.path.join(BASE_PATH, 'small_dataset')\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "VALIDATION_DIR = os.path.join(DATASET_DIR, 'validation')\n",
    "TEST_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "TRAIN_VIRAL_DIR = os.path.join(TRAIN_DIR, 'viral_pneumonia')\n",
    "TRAIN_COVID_DIR = os.path.join(TRAIN_DIR, 'covid')\n",
    "TRAIN_NORMAL_DIR = os.path.join(TRAIN_DIR, 'normal')\n",
    "VALIDATION_VIRAL_DIR = os.path.join(VALIDATION_DIR, 'viral_pneumonia')\n",
    "VALIDATION_COVID_DIR = os.path.join(VALIDATION_DIR, 'covid')\n",
    "VALIDATION_NORMAL_DIR = os.path.join(VALIDATION_DIR, 'normal')\n",
    "TEST_VIRAL_DIR = os.path.join(TEST_DIR, 'viral_pneumonia')\n",
    "TEST_COVID_DIR = os.path.join(TEST_DIR, 'covid')\n",
    "TEST_NORMAL_DIR = os.path.join(TEST_DIR, 'normal')\n",
    "\n",
    "\n",
    "def createDir(path: str) -> None:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "\n",
    "createDir(DATASET_DIR)\n",
    "createDir(TRAIN_DIR)\n",
    "createDir(VALIDATION_DIR)\n",
    "createDir(TEST_DIR)\n",
    "createDir(TRAIN_VIRAL_DIR)\n",
    "createDir(TRAIN_COVID_DIR)\n",
    "createDir(TRAIN_NORMAL_DIR)\n",
    "createDir(VALIDATION_VIRAL_DIR)\n",
    "createDir(VALIDATION_COVID_DIR)\n",
    "createDir(VALIDATION_NORMAL_DIR)\n",
    "createDir(TEST_VIRAL_DIR)\n",
    "createDir(TEST_COVID_DIR)\n",
    "createDir(TEST_NORMAL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "\n",
    "def generate_sets(source: str):\n",
    "    allFiles = os.listdir(source)\n",
    "    np.random.shuffle(allFiles)\n",
    "    return np.split(np.array(allFiles), [int(len(allFiles)*0.7), int(len(allFiles)*0.85)])\n",
    "\n",
    "\n",
    "def saveAndSeparateFiles(src_dir: str, train_dir: str, val_dir: str, test_dir):\n",
    "    train_fnames, val_fnames, test_fnames = generate_sets(src_dir)\n",
    "    for fname in train_fnames:\n",
    "        src = os.path.join(src_dir, fname)\n",
    "        dst = os.path.join(train_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for fname in val_fnames:\n",
    "        src = os.path.join(src_dir, fname)\n",
    "        dst = os.path.join(val_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(src_dir, fname)\n",
    "        dst = os.path.join(test_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "create = False\n",
    "if create:\n",
    "    saveAndSeparateFiles(ORIGINAL_NORMAL_DIR, TRAIN_NORMAL_DIR,\n",
    "                        VALIDATION_NORMAL_DIR, TEST_NORMAL_DIR)\n",
    "    saveAndSeparateFiles(ORIGINAL_COVID_DIR, TRAIN_COVID_DIR,\n",
    "                        VALIDATION_COVID_DIR, TEST_COVID_DIR)\n",
    "    saveAndSeparateFiles(ORIGINAL_VIRAL_DIR, TRAIN_VIRAL_DIR,\n",
    "                        VALIDATION_VIRAL_DIR, TEST_VIRAL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:33:08.779744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'covid': 2531, 'normal': 7134, 'viral': 941}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmFUlEQVR4nO3deXxcdb3/8df3nDkzk8kySdqm6Z4uadpSKKWFsG+C7AEEQUToFRQRFb3cB9rrD665ynW5qFcWZbsqiiAgciFQFtksVqBlaUtaaLovSZc0mWSyz5zl+/vjTDdamrRJ5pyZfJ+PRzRNzsz3M2Hec77nfL/ne4SUEkVR/EfzugBFUQ5MhVNRfEqFU1F8SoVTUXxKhVNRfEqFU1F8SoVTUXxKhVNRfEqFU1F8SoVTUXxKhVNRfEqFU1F8SoVTUXxKhVNRfEqFU1F8SoVTUXxKhVNRfEqFU1F8SoVTGVBCiNFCiKcO43Edg1FPJhNqDSElHYQQASmldZDfd0gp89JZk98FvC5AyVxCiJ8Bm6SUv0n9uxpoB74spZwphPgX4AIgDOQKIaqAZ4EiwABuk1I+60XtmUB1a5X+eBy4cq9/XwG8+4ltTgDmSSnPBHqAS6WUxwBnAL8QQoi0VJqB1J5TOWxSyqVCiBIhxGhgBNACbP7EZq9IKWOp7wXwYyHEqYADjAFGAtvTVXMmUeFU+usp4HKgFHdP+kmde31/NW6I50gpTSHERtwur3IAKpxKfz0OPAQMB04DQgfZNgo0poJ5BjAhDfVlLHXMqfSLlHIlkA80SCm39bL5o8BcIcR7uHvRVYNdXyZTQymK4lOqW+tjZfMXhIGxuMdzpcCoT3w/EsjF/e8YEHpnR97UH0UBO/XVBcQO8NUArAPW1s6r3ZHO16T0ndpz+kTZ/AXDgNl7f0kppwohDuHQo6Uzf/rPcg+x6XbcoK4BVgCLgSW182pbDvF5lAGmwumBsvkLBHAMcC5QKaWcLYQY2+8nls09+TPuHKizn2uBJbhhXVg7r3b5AD2v0kcqnGlSNn9BFPislPJ8kOcLoZUMfCux7vzp/50z8M8LuGORrwAvAi/WzqttHaR2lBQVzkFUNn/BZOByKZ0LQJwghBjkY/xBDefeLGAR7jDKk6oLPDhUOAdY2fwFISnl53Dsm9D0k9I7PS1t4dxbAlgAPAK8UDuvNpnm9rOWCucAKZu/4AhpW19HiGuEphd4U4Un4dxbM/AYcE/tvNo1HtaRFVQ4+6Fs/gJDSvlFbOtmETCO8boeH4RzFwd4Hvhl7bzahV4Xk6lUOA9D2fwFASfR9TURMG4TulHqdT17+Cace/sA+CXwRO282k+9nlPZnwrnIXBD2flVtMAPNCM00ut69ufLcO6yBrgd9wSSetP1gQpnH5TNX6A7ic7r0QLVmhEa5XU9n87X4dxlKfD92nm1L3ldiN+pcPZi3M2PfU4Y4bs1IzTG61p6lxHh3GUhcGvtvNpPXpytpKhwforR190zQY8UPaLnFZ3idS19l1HhBJC4l5v9e+282lhvGw81GXPJmBDih0KIsw7w89OFEM8PVDsjqr4rxtzwULVRPK4us4KZkQRwQ6Ft11AdvdbrYvwmY65KkVL+x2C3Mfr6Xx8fLpv9Jz1SMHmw21JSpLTv3d44HPgD1dGrga9RHd/ocVW+kLY9pxDiWiHEh0KI5UKIR4QQE4QQr6V+9poQYrwQIiqE2LjrSgwhREQIsUUIYQghHhZCXJ76+blCiFVCiEXA5/pbW8nlPwiOufG3DxvDxv1TBTO9Zm9ua5+VNCtS//wssDwV0iEvLeEUQhwB/D/gTCnlLODbwL3AH6WUR+FeIX+3lDIOLMdd7gLgIuBlKaW513OFcY9TLgJOwb228bCNuOTf54RGla82CkvnCU3PmG5+NtA6LPNeO/7JS9wKgD9RHX2E6mi+F3X5RbrejGcCT0kpmwBSq7GdgDvVC9x5mSenvn+CPcstfiH1771NAzZIKddI92zWnw6noEh5pSj5fPUtOZPnLtJzi9RaNh64ZXustUBgfMqvvwQsozpamc6a/CRd4RS4Z+YOZtfva4DzhBDFwBzg9YNse1jyjvxMTvTELzydM2nuzzUjrFZ/80Dpts62eXrPiF42mwQsojp6czpq8pt0hfM14AohxDCAVPDewt0zgrvY0yIAKWUH7kW+dwHPSyntTzzXKmCiEGLXseFVh1LIsHNuml540tUfhkZNvUQtaOyRpOM82NWi93HrAHAX1dEHqY5+2l42K6XlbK2UcqUQ4r+AhUIIG3eWyM3A74QQtwI7gS/v9ZAngL8Apx/guXqEEDcAC4QQTbihntlbDZHySpE78zNfzJ1x+n1aKHdIH8t4raq+tXmi5vS21/ykrwIVVEcvozreNBh1+c2QmIQQKa8M5s44vToy9YRbhW5kzPDRofP/JIScWKL7rdbt4cDh91o2AlVUx2sHsCxfyvqzk5HyytzcmWc9HKk4+XvZHUz/k47k5y3NPf0IJkAZ8CbV0RMHqCzfyupwRsori/NnX/DXyNQTrhKaltWvNRPMqm9vPlWzigbgqQqBv1Ed3W/GWDbJ2jdspLxyVP6cqmdzJs05R5338Z7WaZm/MVsH8lg/F3ie6uglA/icvpKV4YyUV44rOPbSZ3PKjj65962VdLh5e6w1qhEc4KcNAX/J1hlFWRfOSHnlxIK5lzwdHn/ksV7XorhKtne1X6/1OqZ5uAK483IvG6Tn90xWhTNSXjk594gz/xCecNRcr2tRUkzHebAzNtjHFTrwWLYdg2ZNOCPllWNyJh97T6TiRNWV9ZHz61ubJ2tOXhqaCgLPUB09Pg1tpUVWhDNSXlkcGjPjzryjPnu2EJo6++MToZZkzx2yfXgam8wFXqA62uuklEyQ8eGMlFfmGiPKfpg/96JLhaarcUyfkI7kzuamLiP9p8qLcAM6CLe7SK+MDmekvDKoF5TcGj3usmu1QEhNYPeRmfXtsTN0q9ij5scBf830ubgZG85IeaUmAqHroidc8U0trObK+onosqz7zNZ0HGcezMm41wxnrIzsBkbKKwVwaf7cqpsDecXDvK7Hr5pebqJlYQsICI8NM+b6MWjBPZ/HdqdN/W/rSTYm0QyNMdePITw2jNVmsfmezdhdNiM/N5KCOe7dJTbdtYnR147GKDr4DummbbGWIo3BGjo5FDdQHV1Gdfw+rws5HJm655wdnnjMN8Jjpk/3uhC/MltMml9pZnL1ZMr/qxzpSOKL4/tss/O5neSMz6H8jnLGfnUs2x7dBkB8cZzCkwqZdNskml50LwBpW9pGzoScXoM5fHtX+42DN6Z5OO7K1Hm4GRfOSHnlCD1/+Hfyj/ps1pwyHyzSkThJB2lLZFISKNq3o9SztYfcGe4qIaHRIZJNSay4BTpIUyItCRpIW9L8t2aGn3fwE6/SdOQDHb5b4dLAXfbEo5tLHb6MCmekvNJA6F+LHv/5s0Qg6OtLo7xmFBkMP3c4q/9tNau+swotRyN/5r6H5uHxYdrebwOga30XZrOJ2WJSeHwh7bXtbPzFRkouKSH2eozCkwrRQgd/u5y7Jd40VXf8ePw/Efi110UcqowKJ3BR/jHnXx4oGOHjWyL4g91p0760nal3TmXa/0zDSTi0vtW6zzYjLhiB3Wmz9va1NL/STM6EHNBAj+iU3VLGlOop5EzIoW1ZGwVzC2j4XQOb791M19qu/doLtSR7fkybn4//v0R19JBWzfBaxoQzUl45PTRmxg3hCbOO8rqWTNCxsgNjuEGgIIAICArmFuwXKj1HZ+xXxjLlR1MYe8NYrDaL4Ih956Y3PttIyUUlxN+Jk1OWw5jrx7DjqR37bCMdyU9izV3B1JKmPnYf1dGMWczN739MACLllYVCN76ZP/u8SjUDqG+MYQbd67pxEg5SSjo/6iQ0KrTPNnanjWM5ALQsbCG3Ihc9Z8/SPontCcxWk9xpuThJZ/e7xTGdfZ5nekNHy9ma6dWY5qGI4i6rmhF8P5SSGjaZlzfr3EotlFvodT2ZIjI5QsGxBaz9wVqELgiPD1N0ehGx190TNsVnFpPYlqD+oXp3qGVMmDHX7Xuvph1/3cHIy9w7HRYeX8imuzfR/LdmSi7dM/lGdFnWA2ZLhMz5yDyb6ugXqI4/7nUhvfH9GkKR8sqjA9GRtxWd+ZWL1fS83qR/DaEb1zU2fkPrybSpctuAaVTH27wu5GB83a2NlFeGgXn5cy46WgXTf4p3dLdnYDABRgF3eF1Eb3wdTuCccNnsI4yi0er+JT4jTUfe778xzUNxE9XROV4XcTC+DWekvLIU3bgkb+aZ6sJpHzqrPt40XbP9OKbZVzrwK6+LOBhfdhVTJ4Guyp91zgwtlDsQq7UdlNW2k6YFv8TuaEEIjbyjz6Fg7sW0vvkIXWsXgxDokUKGnf8dAvn7D+W1vfcsHctfBgl5s86h4NiLAWj5++/pXv8+wZKJDL/w3wDoWPE6Tk87BXMvHuyXNWiCrcnEf8u2YWT+wmknUx2tojpe43UhB+LXPedRWjivMjz+qKPT0pqmU3TG9Yz56v2UXvNz2j9YQLJpMwWVlzH6unsZ/eV7yJl8LPG3/rzfQ5M7N9Kx/GVKr/0lo667h+51SzBjDTiJThINHzP6unuR0iG5cyOOmaBzxavkz74gLS9rMEgpuaO5uSMDxjT76idUR335WnxXVKS80gCuzZt51jihBwZ6tbYDCuQVEyqdAoAWimAMG4fd3owWiuzeRpo9cIDxArO5ntDoaWhGGKHphMbNpGvN24BA2hZSSqSVRGg6bUueJn9OFSKDz21V1He0nKeZfp4JdKhmAF/0uogD8V04gbnCCI8MjZk224vGrfgOkjvWExrt3s+15c0/Uv+bf6Hzo79TeMqX9ts+OHwCPVtWYHe34Zg9dK9/D7utCS0UIVJxItsevplAdCQilEty22oi5Zk7X1902/b9ydZsnNP8A6qjvvvE9NU4Z6S8Ugd+mj/7gmNzJs05rdcHDDAn2c2Ox+YTPeFKIhX7XmUUf/tJpGVSeMr+S6S2L/8bHUsXIIwwxvBxiECI4s98dZ9tml+8m/xjLiCxfS09G5ZilJRReOIX9nuu/hnccc6vrNvZ+G2tOxOHTvriS1THH/W6iL35bc85C90oCY2bmfZT3NK22Pl/PyZ3xun7BRMgd8bpdK3+5wEfmz/rs4z6l7sovfpnaOF8jKLR+/w+uWMdAIGiMXSueJ0Rl8zH3LkJM9Yw8C9kkBQ1dndkcTAB/tXrAj7JN+GMlFdqwOfyZpw+RjNCaV3iQkpJ84t3YQwbR8Fxl+7++d7h6Vq7GKN47AEfb3e2AmC1NdK1+m0iM/bd6bf+409ET74aHAtkal6q0JBWYmBfyCCRliPva4v5p4s1OOZQHU17b+1g/NTPPgJNHxcuOzrte81Ew0d0rnwDY0QZW3//LQCKTr2Wjg9fwYzVg9AIFIyg+JxvAGC1N9P80t2M/Px/ArDzmR/jdLeDplN89o3o4T2fLV2r3yZYWr57CCY0ehpbf/sNjJIygiWT0vxKD88Z9fHmI3Q7nUtceuUWYKHXRezii2PO1Ljm7ZGpJx6fd+RZ53ldT+Ya+GNOI55MvNW0zQhrWTN0cjAO7pzbNV4XAv7p1k4FJoXHH6mm6fmIlJIf7ox1DJFggpuHb3pdxC5++aOfoecWoReMmOJ1Icoe5Q2drRfqyWwa0+yLL/plvVvPwxkpr8wD5kYqThwlhLrBrW902/YDiZahuFD3cOB8r4sAH4QTmAlowdJytfyIj3x5ayxWosmhGE6Aa70uAPwRzs8ESyYF9ZyCUq8LUVzRxu6OW7RuP609m24XUh31fNkVT8MZKa8cCUzOmXLcRC/rUPaQliN/3R6zva7DY0HgSq+L8HrPORchpDF8gurS+sSp9W3NszQ76nUdPnBp75sMLs/CmZoRdGZo9DQj3TOClAMLtJmJX9rxQb9+NkOcRnXU0/ell3vOMqAoNHramN42VAaflJLqxuaOsCb03rceEoLA2V4W4GU4KwAZKBqdGXPYstykhs7Wi4femGZvPL0q3stwzhVGqFPPLRrnYQ0KQI9tP5hoCfW+4ZBzPtVRz9Zi8SSckfLKCDAxPP6oIqFpqhvlsWsaWppLNZmNF1H31yjgSK8a92rPOREgOHKy6tJ6rGBnT+d3ta5svk6zvzy7t6dX4ZwO2IHCUhVOD0lbynviMcvrOnzuBK8a9iqcc7VItEcL56tZQR46aUs8doxuqTHNgxs6e85IeWURMDJUOqVAZP66pxkr0GYmf2XHC72uIwNMoTrqyVRGL/acZYATiJYO5bmbnrutsbktR41p9pUnSyZ6Ec7RAHpesToJ4ZHxDR2tl+nJobDsyECZ5UWjXoRzEtClR7zpKgx5Pbb9UKIlLYt1Z5FpXjTqRTgnAJ1aOF/tOT1wVUNL82ghI71vqewl+8OZut/mML2gJCACxlC9kNczeU09nfNFp/pQPHQVXjSa7j3ncMAODh+vurRptmtMU1NnyA9HHtXRAy9aPIjSHc4SQAtER6pwptnx9W2xuZoa0+yH8nQ3mO5wjgaklpOv3iRppLebybvsVvU3759R6W4w3eGcAHSJYE5umtsd0r7fGGvLFcJPq/tnopHpbjDd4RwGJDUjrMKZJuMaOuNXaAk1ptl/WR/OQiA5XLTphpMY6otIDb6EbT/YE/PFAslZIO1nudPW1UndD6UA2PpGwQ+Ki0KOnnSE1WnrPR22kWi3g2ark2O1yFynxcmTzRTIGAVaM4VasygMxESR0aIVh1u0orCphdS0sz74fENrbKwm1cm3gZH2PWfawjlVbAlpOBUCOTuoOXkAQU0GgpqVV2RYedANxPv0XElHmJ22nuiwjUSbHTLjTthqkblOzMlzYhSwK9RNoijQIoqCLVpRaKiFOrepp+s2OkaAGjoZIGlfxzZt4RwvdubYUmy00TpyAsHZ/XnTBDVpBDXL2BPqvulLqJso0ppFodEiioyYVhRq0YrDlhbMqFBLW8q7WmNJTRdqJtDASfuUx3SewQvrQiZCmt2oeXStWL9Cbek9HY6R3B1qJ9eJSTfUzUS1Zgp1t/tdbLRohZ6G+tj6tlilbqnFugZWVoczCKCJzOtnBTVpBIOWUYRFf0Ld6uRYrU7Eick8pzkV6hiFeqr73f9QS0fX203zHjsezby/su9ldTg1yMxwHq79Q93ap8clbGF22W6o43bIjO8Odb7TTIFopkDsHeqYiEZa9aKQhaPfuiMWy9NRJ4EGXlaHU+z+H+WgQro0Qrob6nGHEOoeG8IqmIMl7eFM+yVjuqbyOVjCOhl14irDOOluMJ3hFACOTGOLijJwetLdYNrD2WVi2Y5M+6eQovRTVodzdyBNJ/0vVFH6qSPdDaYznIld3yRtFU4l47Slu8F0hnN3IBOWTBxsQ0Xxob7NLR1A6Q6nAEioPaeSebanu8F0h1MH6DJlZxrbVZSBsCXdDaYtnDV1po173KnHumVrutpVlAFSn+4G0z0JoRUI7uxU4VQyTtaHczsQ3tahwqlknKwP5zYgvLHVaUlzu4py2KSUNtCQ7nbTHc6tQHBtzIk7UqqJfEpGEEKspjqeTHe7XhxzOj0WdnsCtfdUMkWtF42mO5wtgARo7HS2pbltRTlcQyKcO1Ntii1tUoVTyRQfetFoWsNZU2f2ADuAnNXNas+pZIwhsecEWAPkf7DNVuFUfE9K2QRs9KJtL8K5Gght75Dd7Qk13qn4mxDiTarjnowseBHObaROCm2OOxs9aF9RDsVCrxr2KpwAYuVOZ70H7SvKoRg64aypM7tw+/AFf99orVdzERS/klK24tHJIPBmzwnwHlBQ3yY7W3po9KgGRenNQqrjnq135VU4V+/6ZkOL6toq/iSEeM7L9r0K52bABvTFDfbq3jZWlHRLTXZ/1ssaPAlnTZ1pAh8Dha+utzZ2q5URFJ9xJG9THW/ysgav9pwA7wB5loNcE3M+9rAORdmPromnvK7By3B+hDveKRZttld6WIeiHMj/eV2AZ+GsqTPjwCqg6G/rrE2qa6v4heXIJVTHN3tdh5d7ToA3gXxHIlc1OWrvqfhCQBP3e10DeB/OXV1b7bnV5vse16Io2I7sBJ7wug7wOJw1dWYb7rVyw97b6jRua3c870ooQ5steZzqeJfXdYD3e06A14AIwJub7Hc9rkUZ4oK6P7q04I9wfoy7tlDkrx+bH6sTQ4pXEpZcSXX8Pa/r2MXzcNbUmRbwIjC8x8Jett3+wOualKEpoHGH1zXszfNwpixJ/b/+WK25xHak7Wk1ypDTY8kGXRN/8bqOvfkinDV1ZivujKGSTXHZsXKns9TjkpQhxpH8lOq4r3YKvghnystACBCPLDf/qW5Nr6RL0paxiCEe8rqOT/JNOGvqzE24wyoj6pqd1o+bnGUel6QMEUmbX1Ed990NnX0TzpQa3GEV8fAy802191QGW48lm/OC4ude13EgfgvnOmAlMGJ1sxNftt1Z0tsDFKU/2hLyP6iOd3tdx4EIv63hU1VhTAZuBzYNj4jQby4IfyscEBGv68omrT2Sr9R0s6LRQQj4XVWYXy1OUtfk7P59YViw7Ma8fR7XY0lO/X0nCRssBy6fHuA/zwgD8L1XenhxrcXRpTp/vDQHgEeWJ4l1S759fCi9L7CP2hJyQ0FITPZq6cveBLwu4ADW4w6tzGrqktteXW+9ceFU4wKvi8om336ph3OnBHjqiiBJW9JlwhOX7/n8+7eXe4iGxX6PC+nw+rxc8oIC05ac/PtOziu3mD5c5616mw+/nsfVT3dRu8NmSrHGw8tNXrrav5+rXab8ZsFP2nwZTPBft5aaOlMCTwE6YPxuqfl+rNvZ4XFZWaMtIXlzk8X1sw0AgrqgcK8gSil58iOTq2bu/7kthCAv6G5rOmDaIABNQNKWSCnpNsHQ4c63ktx8XBBD3z/kftDc5bxT+vP2F7yu42B8F06AmjqzEXgeKLUc5OMrrJe8rilbrG9xGBERfPnZHmY/0MFXarrpTO7Zefxjs83IXEH5MP2Aj7cdydH3d1ByZztnTwpQOTZAfkhw2XSD2Q90MrFQIxoSvLvV5uJpRrpe1iExbWklbeZ5XUdvfBnOlJeBTiD3pbXWxo932su9LigbWA58sM3h63MNln4tj1xD8NNFe0YR/lxrctXMTw+VrrnHovW35LNkq82KRnfc/rsnhVh2Yx6/OCfM7W8k+OHpIf73gyRX/KWLO9701yjFljZ536hftPt+YTnfhrOmzuwGHgVKAO58K/lSlynbva0q840tEIwtEFSOdbutl88I8MF290SQ5UieXmVx5UHCuUthWHD6hAAvrbX2+fnSbW5Ypw7T+ONykyc/H2FFo82aZn9Mvol1ywZHcovXdfSFb8OZ8i6wAiht6pI9j68wPV1HNBuU5mmMi2rUNblheW2DxYzh7tvg1fU204ZrjC048NtiZ6dDa4/bBe42Ja9usJg2fN9tb38jwQ/PCGE6YKd6y5qALnOQXtAhsB3pbGhxrplyd7vV+9be83U4a+pMB3gYt87wM6usNR+p7m2/3XNemKuf7uao+zpYtt3h+6e4Qx2Pr9i/S7u13eH8R91rj7d1SM74QydH3dfBsQ91cvakABdO3bP9M6tMjh2tMzpfozAsOGGszpH3dSAEzCo98DFsOq2NOY/NebDjDa/r6CvfjXMeSFWFcRpwHbBheESE7zkvfFNuUOR7XZeSOba1OxufW21V3PBcd9LrWvrK13vOvfyDvbq3//tB8ilHqql9St90mbJn0Wb78kwKJmRIOPfq3gog8toGe/PrG+xXva1KyQRSSt7eYv/g83/pyrgF5DIinAA1deZO4EGgFNDvXpx8e32Ls8rjshSfW9HovHrX4uSdXtdxODImnCkfAC8A4wB+tDDxTFtCxrwtSfGr+jZny3OrrctTs84yTkaFM/VH/ivuLQRLm7tl4q53Ek8kbemvUW7Fc7Fup+3JleaF33+tJ+51LYcro8IJu+9Q9gBgAfnvbnUaf7fUfFJd+6ns0mXKxJ9rza/f8nLPh17X0h8ZF06AmjqzGbgHKAbCL6yx1j9bZ9V4XJbiA5Yjnac/Nn/y8jr7z17X0l8ZGU6AmjqzDvcE0Wgg8PAyc/mbm6yMGWBWBp6UkpfWWn96cqV1R6YeZ+4tY8MJUFNnvo17X4vxgPbzt5Jv1u6wM+6UuTIwFqyxFjz4vnljTZ3pj4m8/ZTR4Ux5AXgVmABw2+uJ51c22mppzSFmwWpz4YPvm/NSF0xkhYwPZ6r78hjwPjBBAt9/LVGjAjp0vLzWeuuB980vpM5FZI2MDyfsvqXDA8By9groChXQrPfaemvxr99NXlFTZ273upaBlhET3/uqqsIIAV8HjgY2CuCOM0MXHjlSn+NpYcqAc6SUNXXWot8tNa+uqTO3eF3PYMiqcAJUVRhB9gR0E8CtJwZPO2VC4HQPy1IGkOVI+5Hl5mv/t8r6Wk2dudHregZL1oUTdgf0a8AcYDPgzJtlzLpkWqBK10RWdOWHqoQlk/e/l6x5bYP9rzV1Zr3X9QymrAwnQFWFYQBfBD6DG1DrvCmBidcfY1wZ1IU/F1JVDqotITvvXpx8fEmDPb+mzmzyup7BlrXhBKiqMARwPnAlsBXomTNKG/GvJ4S+UBASxd5WpxyKja3Otp8tSvy+oV3+tKbOHBJrSWV1OHepqjCOx+3mxoD24hwRuv3U0MWTi7XpHpem9ME/Nlkf/c87yQcshwdr6swer+tJlyERToCqCqMCuBl3sertAN86Lnj8mRP1s9VxqD+ZtrQe+dB865lV1p3Ai9ky86evhkw4AaoqjGHAjUA5sAWwzyjTx90wJ3h5blAUeFudsrftHU7jr95JvvHRTue/aurMWq/r8cKQCifsPlF0KXABsAPoKskV4VtPDJ5fMVw/0tvqFEdK5/UN9of3vZt8wXS4u6bOHLK34hhy4dylqsKYjbsXdXBDypVHBKZ/brpxQY4hcj0tbohq6ZYt9yxJvPXeVudx4K/ZNE/2cAzZcAJUVRglwJeBGbhncxMjc0XOLScEz50+Qj/K2+qGDtuR9qLN9sr73ksu6jK5r6bOXOF1TX4wpMMJUFVh6MDpwFW4qytsBzhvSmDilTONc4tzRImH5WW9Ta3OxnuXJJfXNTsvAo8NlWGSvhjy4dylqsIYCVwLHInbze0MaIjrZhtzzpoUOEPdwHdgtSdk/M8rzPefX22tBP4IvJ8NF0gPJBXOvVRVGBpwHO7Monzcrq45LEeEbjo2eNoxo7TjdE14f1+BDJawZM/CTfaHv/0gWddt8RzwQk2d2el1XX6kwnkAVRVGBDgbqAJsYBsgpw7TotccZZw8s0SbrUJ6aExbJhc32Mseej+5rqWHZcCjNXVmg9d1+ZkK50FUVRgjgMuA44FuoBGQZYUif96s4ImzSrW5AU3sfwtoZbekLROL6+2lv19mbmzqkvXAn4GlqgvbOxXOPqiqMCYBFwOz2CukYwtE7jVHGZVHl+rHqOGXfbX2yOZFm61lj9Wa2zuS7AT+AixJXRiv9IEK5yGoqjDKgAtxL0VL4p44csIB9MumG9NPnaDPHZWvTfCyRi9JKdkUl2sWrLZW/m2d1SqhBXcR8Hdr6syMuomQH6hwHoaqCmMccB5QiXtzpSagC2B2qTb84mnG3OnDtZlDZW/a2iOblm+3Vzyzyty2rkUmgXXAAqA2tQi4bwkhNgJzpZS+uwRNhbMfqiqMQtyzu+cBhbgBbQKkJhBnTwpMOHm8fsTUYdr0bAtqZ1K2fbTTWfHiWnPde1sdC5DAIuANYFM6jimFEAEpZb+6ySqcWS41kWEacBbucakA2nG7dbuDevxYvWJikTapKEyJEMLDig+dI6Wzo0PWr4k56/652d7yTr1tSXeBuAbcQL5XU2ce8n1JhBBlwIu4wT4x9XwXAxXA/UAEd098nZSyRQjxd+At4CSgBrgIWIp7qDECd6z633HHq5+QUt6WaucZ3BtghYG7pJQPpn6+ERXOoaGqwijAnQ54CjAdN6gdQCvusAxjC0TuaRMCE48o0SaOj2oTC0KiyKt6P40jpRPrlo1b22X9hzvs9a+ss3e29MgI7uuJ4QbyA2Bbf/aSqXCuxQ3IMiHEk7ih+y7wLSnlQiHED4ECKeV3UuH8SEp5U+rxfwcWSym/J4T4NvA93KDGcEM9S0rZLIQollLGhBA5wLvAaamfb8Sn4VTDAAOsps5sA94B3kkFdTrup/w03GtJRX2bjD9aa67EvVs3pXki55hR+qjyYq10XFSMKsnVRhWEKNbStHu1HGm1JYjt7HR2bGyVDR/ttLcuabBbOk3yASO12U5gCfAxsDl1Q+OBskFKuSz1/fvAZKBQSrkw9bM/4J7t3eWJTzx+131yaoGVUsptAEKI9bh7y2bgZiHEpantxuFeNujrdW5VOAdRKqiLgcWpS9XG474p5gCTUpuJ7R0y8cIaawewAffYjZwAevkwrXB8VCsszRPRERFRWJwjCvOCIj8cICcUEDlBnVBAw9DEgS8Wd6SUSZuehEVXjyW7uy26ukzZ1Z6QnTs6ZWxLXMZWN9vNG1tlj3RnRO06Lha4HyRvA8uAdYM853XvWzjauMfvB/PJGUW7Hu984rkcICCEOB33kOMEKWVXam8bPsxa00aFM01SZy3Xpb5eqqowcoAxuHfqLgem4H6iS4BuC+3DHY754Q6nBXeGUg/um20/OQH0gIZmS6Tl4DgSaTvsfcCi4+4BDdw3ZRg3gA5QlHruNcBHuBehNwBtHk4UiAMtQohTpJT/AK4BFvbymIOJAi2pYE7DnVTieyqcHkldq7g29bUIdi+KXYIbmEJgVOprJG6IDdxA7ROa7k8/XylwT9okcU9QxYFVuOv5NuEel8WAdh/O2JkH3C+EiADrcS/tO1wvATcKIT4E6nAPO3xPnRDKIKmucQ7uns8Agrh7RXmArwTu0E6338calQNT4VQUn1KrzimKT6lwKopPqXAqik+pcCqKT6lwKopPqXAqik+pcCqKT6lwKopPqXAqik+pcCqKT6lwKopPqXAqik+pcCqKT6lwKopPqXAqik+pcCqKT6lwKopPqXAqik+pcCqKT6lwKopPqXAqik+pcCqKT6lwKopPqXAqik+pcCqKT/1/apAIWOeA+lwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "normal_train = tf.io.gfile.glob(TRAIN_NORMAL_DIR + '/*')\n",
    "viral_train = tf.io.gfile.glob(TRAIN_VIRAL_DIR + '/*')\n",
    "covid_train = tf.io.gfile.glob(TRAIN_COVID_DIR + '/*')\n",
    "\n",
    "# Plotting Distribution of Each Classes\n",
    "image_count = {'covid': len(covid_train), 'normal': len(\n",
    "    normal_train), 'viral': len(viral_train)}\n",
    "print(image_count)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(image_count.values(),\n",
    "        labels=image_count.keys(),\n",
    "        shadow=True,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our Covnet Model\n",
    "In this case we are doing a multi class classification, our total clases are 3:\n",
    "- Viral CXR\n",
    "- Covid CXR\n",
    "- Normal CXR\n",
    "\n",
    "Our neural network will output neurons as 3 classes that will calculate the probability of being one using the softmax function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10606 images belonging to 3 classes.\n",
      "{'covid': 0, 'normal': 1, 'viral_pneumonia': 2}\n",
      "Found 2273 images belonging to 3 classes.\n",
      "{'covid': 0, 'normal': 1, 'viral_pneumonia': 2}\n",
      "Found 2274 images belonging to 3 classes.\n",
      "{'covid': 0, 'normal': 1, 'viral_pneumonia': 2}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False  # randomly flip images\n",
    ")\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "evaluate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "print(validation_generator.class_indices)\n",
    "\n",
    "test_generator = evaluate_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "print(test_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_batch, y_batch in train_generator:\n",
    "# \t# create a grid of 3x3 images\n",
    "# \tfor i in range(0, 9):\n",
    "# \t\tplt.subplot(330 + 1 + i)\n",
    "# \t\tplt.imshow(X_batch[i].reshape(150, 150), cmap=plt.get_cmap('gray'))\n",
    "# \t# show the plot\n",
    "# \tplt.show()\n",
    "# \tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:33:10.585015: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-07 15:33:10.594478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-07 15:33:10.875349: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:10.875391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.215GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-11-07 15:33:10.875417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-07 15:33:10.877197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-07 15:33:10.877261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-11-07 15:33:10.878849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-07 15:33:10.879270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-07 15:33:10.882357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-07 15:33:10.884067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-07 15:33:10.890343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-07 15:33:10.891243: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:10.892030: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:10.892047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-11-07 15:33:10.893880: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 15:33:10.895249: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:10.895275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.215GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-11-07 15:33:10.895301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-07 15:33:10.895325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-07 15:33:10.895337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-11-07 15:33:10.895347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-07 15:33:10.895358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-07 15:33:10.895369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-07 15:33:10.895380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-07 15:33:10.895391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-07 15:33:10.896068: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:10.896725: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:10.896741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-11-07 15:33:10.896791: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-07 15:33:11.718818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-07 15:33:11.718841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-11-07 15:33:11.718847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-11-07 15:33:11.766676: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:11.766717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1489] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-11-07 15:33:11.767629: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:11.768379: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-07 15:33:11.768414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6575 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-11-07 15:33:11.768818: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 148, 148, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 34, 34, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 3,505,347\n",
      "Trainable params: 3,504,579\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import backend\n",
    "\n",
    "# We want to make sure we start from the start when training our model everytime we run it.\n",
    "backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-5,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "opt = optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# try with metric categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hivini/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass classes=[0 1 2], y=[0 0 0 ... 2 2 2] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "2021-11-07 15:33:12.934038: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-07 15:33:12.934555: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2208005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 15:33:13.836465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-07 15:33:14.104395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-07 15:33:15.312335: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-11-07 15:33:15.411658: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 83s 196ms/step - loss: 0.8962 - accuracy: 0.6413 - recall: 0.6046 - val_loss: 1.8882 - val_accuracy: 0.2609 - val_recall: 0.2033\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.26089, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 2/400\n",
      "331/331 [==============================] - 42s 126ms/step - loss: 0.6009 - accuracy: 0.7399 - recall: 0.7166 - val_loss: 0.4696 - val_accuracy: 0.8108 - val_recall: 0.7831\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.26089 to 0.81082, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 3/400\n",
      "331/331 [==============================] - 42s 126ms/step - loss: 0.5360 - accuracy: 0.7632 - recall: 0.7448 - val_loss: 0.3800 - val_accuracy: 0.8324 - val_recall: 0.8240\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.81082 to 0.83238, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 4/400\n",
      "331/331 [==============================] - 42s 128ms/step - loss: 0.4688 - accuracy: 0.7991 - recall: 0.7842 - val_loss: 0.3682 - val_accuracy: 0.8403 - val_recall: 0.8293\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.83238 to 0.84030, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 5/400\n",
      "331/331 [==============================] - 42s 125ms/step - loss: 0.4610 - accuracy: 0.7965 - recall: 0.7853 - val_loss: 0.3402 - val_accuracy: 0.8592 - val_recall: 0.8526\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.84030 to 0.85922, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 6/400\n",
      "331/331 [==============================] - 41s 124ms/step - loss: 0.4312 - accuracy: 0.8136 - recall: 0.8055 - val_loss: 0.3250 - val_accuracy: 0.8649 - val_recall: 0.8619\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.85922 to 0.86494, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 7/400\n",
      "331/331 [==============================] - 41s 124ms/step - loss: 0.4025 - accuracy: 0.8349 - recall: 0.8268 - val_loss: 0.3259 - val_accuracy: 0.8658 - val_recall: 0.8645\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.86494 to 0.86582, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 8/400\n",
      "331/331 [==============================] - 42s 127ms/step - loss: 0.3712 - accuracy: 0.8471 - recall: 0.8409 - val_loss: 0.2821 - val_accuracy: 0.8874 - val_recall: 0.8843\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.86582 to 0.88737, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 9/400\n",
      "331/331 [==============================] - 43s 128ms/step - loss: 0.3774 - accuracy: 0.8403 - recall: 0.8347 - val_loss: 0.2812 - val_accuracy: 0.8847 - val_recall: 0.8825\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.88737\n",
      "Epoch 10/400\n",
      "331/331 [==============================] - 42s 127ms/step - loss: 0.3684 - accuracy: 0.8520 - recall: 0.8454 - val_loss: 0.2641 - val_accuracy: 0.8900 - val_recall: 0.8891\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.88737 to 0.89001, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 11/400\n",
      "331/331 [==============================] - 43s 129ms/step - loss: 0.3422 - accuracy: 0.8557 - recall: 0.8522 - val_loss: 0.2787 - val_accuracy: 0.8905 - val_recall: 0.8896\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.89001 to 0.89045, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 12/400\n",
      "331/331 [==============================] - 42s 128ms/step - loss: 0.3414 - accuracy: 0.8614 - recall: 0.8582 - val_loss: 0.2441 - val_accuracy: 0.8988 - val_recall: 0.8979\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.89045 to 0.89881, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 13/400\n",
      "331/331 [==============================] - 41s 124ms/step - loss: 0.3199 - accuracy: 0.8641 - recall: 0.8600 - val_loss: 0.2350 - val_accuracy: 0.9045 - val_recall: 0.9032\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.89881 to 0.90453, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 14/400\n",
      "331/331 [==============================] - 41s 124ms/step - loss: 0.3310 - accuracy: 0.8634 - recall: 0.8590 - val_loss: 0.2393 - val_accuracy: 0.9023 - val_recall: 0.9001\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.90453\n",
      "Epoch 15/400\n",
      "331/331 [==============================] - 42s 125ms/step - loss: 0.3007 - accuracy: 0.8754 - recall: 0.8723 - val_loss: 0.2193 - val_accuracy: 0.9085 - val_recall: 0.9076\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.90453 to 0.90849, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 16/400\n",
      "331/331 [==============================] - 43s 130ms/step - loss: 0.2902 - accuracy: 0.8820 - recall: 0.8785 - val_loss: 0.2044 - val_accuracy: 0.9155 - val_recall: 0.9147\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.90849 to 0.91553, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 17/400\n",
      "331/331 [==============================] - 46s 139ms/step - loss: 0.2835 - accuracy: 0.8855 - recall: 0.8833 - val_loss: 0.2019 - val_accuracy: 0.9151 - val_recall: 0.9138\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91553\n",
      "Epoch 18/400\n",
      "331/331 [==============================] - 50s 152ms/step - loss: 0.2720 - accuracy: 0.8903 - recall: 0.8891 - val_loss: 0.1953 - val_accuracy: 0.9177 - val_recall: 0.9160\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.91553 to 0.91773, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 19/400\n",
      "331/331 [==============================] - 40s 121ms/step - loss: 0.2618 - accuracy: 0.8974 - recall: 0.8940 - val_loss: 0.2046 - val_accuracy: 0.9151 - val_recall: 0.9138\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91773\n",
      "Epoch 20/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.2710 - accuracy: 0.8937 - recall: 0.8923 - val_loss: 0.1821 - val_accuracy: 0.9234 - val_recall: 0.9217\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.91773 to 0.92345, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 21/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.2470 - accuracy: 0.9025 - recall: 0.9012 - val_loss: 0.1795 - val_accuracy: 0.9287 - val_recall: 0.9274\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.92345 to 0.92873, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 22/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.2484 - accuracy: 0.9003 - recall: 0.8989 - val_loss: 0.1703 - val_accuracy: 0.9248 - val_recall: 0.9234\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92873\n",
      "Epoch 23/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.2337 - accuracy: 0.9076 - recall: 0.9053 - val_loss: 0.1708 - val_accuracy: 0.9340 - val_recall: 0.9318\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.92873 to 0.93401, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 24/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.2269 - accuracy: 0.9095 - recall: 0.9081 - val_loss: 0.1719 - val_accuracy: 0.9252 - val_recall: 0.9243\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.93401\n",
      "Epoch 25/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.2359 - accuracy: 0.9079 - recall: 0.9070 - val_loss: 0.1655 - val_accuracy: 0.9349 - val_recall: 0.9340\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.93401 to 0.93489, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 26/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.2194 - accuracy: 0.9153 - recall: 0.9136 - val_loss: 0.1597 - val_accuracy: 0.9340 - val_recall: 0.9336\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.93489\n",
      "Epoch 27/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.2082 - accuracy: 0.9193 - recall: 0.9182 - val_loss: 0.1428 - val_accuracy: 0.9424 - val_recall: 0.9410\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.93489 to 0.94237, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 28/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.2080 - accuracy: 0.9195 - recall: 0.9173 - val_loss: 0.1381 - val_accuracy: 0.9459 - val_recall: 0.9454\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.94237 to 0.94589, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 29/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.2058 - accuracy: 0.9196 - recall: 0.9189 - val_loss: 0.1445 - val_accuracy: 0.9415 - val_recall: 0.9402\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.94589\n",
      "Epoch 30/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.2087 - accuracy: 0.9171 - recall: 0.9157 - val_loss: 0.1445 - val_accuracy: 0.9397 - val_recall: 0.9388\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.94589\n",
      "Epoch 31/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1947 - accuracy: 0.9256 - recall: 0.9248 - val_loss: 0.1446 - val_accuracy: 0.9432 - val_recall: 0.9424\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.94589\n",
      "Epoch 32/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.2009 - accuracy: 0.9264 - recall: 0.9247 - val_loss: 0.1659 - val_accuracy: 0.9322 - val_recall: 0.9318\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.94589\n",
      "Epoch 33/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1920 - accuracy: 0.9231 - recall: 0.9223 - val_loss: 0.1479 - val_accuracy: 0.9406 - val_recall: 0.9402\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.94589\n",
      "Epoch 34/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1922 - accuracy: 0.9242 - recall: 0.9225 - val_loss: 0.1319 - val_accuracy: 0.9485 - val_recall: 0.9481\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.94589 to 0.94853, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 35/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1879 - accuracy: 0.9290 - recall: 0.9282 - val_loss: 0.1516 - val_accuracy: 0.9380 - val_recall: 0.9371\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.94853\n",
      "Epoch 36/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1892 - accuracy: 0.9274 - recall: 0.9261 - val_loss: 0.1435 - val_accuracy: 0.9410 - val_recall: 0.9402\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.94853\n",
      "Epoch 37/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1778 - accuracy: 0.9344 - recall: 0.9329 - val_loss: 0.1387 - val_accuracy: 0.9472 - val_recall: 0.9472\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.94853\n",
      "Epoch 38/400\n",
      "331/331 [==============================] - 40s 121ms/step - loss: 0.1792 - accuracy: 0.9337 - recall: 0.9331 - val_loss: 0.1289 - val_accuracy: 0.9507 - val_recall: 0.9503\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.94853 to 0.95073, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 39/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1960 - accuracy: 0.9256 - recall: 0.9245 - val_loss: 0.1141 - val_accuracy: 0.9564 - val_recall: 0.9547\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.95073 to 0.95645, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 40/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1781 - accuracy: 0.9313 - recall: 0.9306 - val_loss: 0.1195 - val_accuracy: 0.9520 - val_recall: 0.9520\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.95645\n",
      "Epoch 41/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1797 - accuracy: 0.9332 - recall: 0.9321 - val_loss: 0.1303 - val_accuracy: 0.9432 - val_recall: 0.9415\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.95645\n",
      "Epoch 42/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1643 - accuracy: 0.9383 - recall: 0.9374 - val_loss: 0.1320 - val_accuracy: 0.9437 - val_recall: 0.9428\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.95645\n",
      "Epoch 43/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1667 - accuracy: 0.9366 - recall: 0.9358 - val_loss: 0.1155 - val_accuracy: 0.9542 - val_recall: 0.9529\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.95645\n",
      "Epoch 44/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1556 - accuracy: 0.9401 - recall: 0.9391 - val_loss: 0.1146 - val_accuracy: 0.9564 - val_recall: 0.9547\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.95645\n",
      "Epoch 45/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1514 - accuracy: 0.9403 - recall: 0.9387 - val_loss: 0.1300 - val_accuracy: 0.9490 - val_recall: 0.9485\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.95645\n",
      "Epoch 46/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1645 - accuracy: 0.9373 - recall: 0.9367 - val_loss: 0.1318 - val_accuracy: 0.9498 - val_recall: 0.9490\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.95645\n",
      "Epoch 47/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1592 - accuracy: 0.9406 - recall: 0.9394 - val_loss: 0.1887 - val_accuracy: 0.9274 - val_recall: 0.9265\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.95645\n",
      "Epoch 48/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1608 - accuracy: 0.9396 - recall: 0.9385 - val_loss: 0.1155 - val_accuracy: 0.9538 - val_recall: 0.9534\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.95645\n",
      "Epoch 49/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1523 - accuracy: 0.9423 - recall: 0.9419 - val_loss: 0.1222 - val_accuracy: 0.9516 - val_recall: 0.9512\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.95645\n",
      "Epoch 50/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1551 - accuracy: 0.9406 - recall: 0.9389 - val_loss: 0.1232 - val_accuracy: 0.9512 - val_recall: 0.9503\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.95645\n",
      "Epoch 51/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1573 - accuracy: 0.9404 - recall: 0.9397 - val_loss: 0.1216 - val_accuracy: 0.9534 - val_recall: 0.9525\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.95645\n",
      "Epoch 52/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1518 - accuracy: 0.9449 - recall: 0.9439 - val_loss: 0.1081 - val_accuracy: 0.9569 - val_recall: 0.9560\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.95645 to 0.95689, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 53/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1416 - accuracy: 0.9512 - recall: 0.9507 - val_loss: 0.1008 - val_accuracy: 0.9591 - val_recall: 0.9582\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.95689 to 0.95908, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 54/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1469 - accuracy: 0.9502 - recall: 0.9488 - val_loss: 0.1097 - val_accuracy: 0.9551 - val_recall: 0.9547\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.95908\n",
      "Epoch 55/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1483 - accuracy: 0.9450 - recall: 0.9437 - val_loss: 0.1063 - val_accuracy: 0.9560 - val_recall: 0.9547\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.95908\n",
      "Epoch 56/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1491 - accuracy: 0.9433 - recall: 0.9428 - val_loss: 0.1268 - val_accuracy: 0.9516 - val_recall: 0.9516\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.95908\n",
      "Epoch 57/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1451 - accuracy: 0.9448 - recall: 0.9442 - val_loss: 0.0998 - val_accuracy: 0.9617 - val_recall: 0.9613\n",
      "\n",
      "Epoch 00057: val_accuracy improved from 0.95908 to 0.96172, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 58/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1392 - accuracy: 0.9498 - recall: 0.9487 - val_loss: 0.1128 - val_accuracy: 0.9595 - val_recall: 0.9591\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.96172\n",
      "Epoch 59/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1439 - accuracy: 0.9491 - recall: 0.9483 - val_loss: 0.1503 - val_accuracy: 0.9388 - val_recall: 0.9388\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.96172\n",
      "Epoch 60/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1221 - accuracy: 0.9528 - recall: 0.9523 - val_loss: 0.1046 - val_accuracy: 0.9595 - val_recall: 0.9582\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.96172\n",
      "Epoch 61/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1279 - accuracy: 0.9499 - recall: 0.9489 - val_loss: 0.1441 - val_accuracy: 0.9410 - val_recall: 0.9393\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.96172\n",
      "Epoch 62/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1244 - accuracy: 0.9530 - recall: 0.9520 - val_loss: 0.1190 - val_accuracy: 0.9494 - val_recall: 0.9494\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.96172\n",
      "Epoch 63/400\n",
      "331/331 [==============================] - 40s 121ms/step - loss: 0.1247 - accuracy: 0.9552 - recall: 0.9548 - val_loss: 0.1588 - val_accuracy: 0.9415 - val_recall: 0.9415\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.96172\n",
      "Epoch 64/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1364 - accuracy: 0.9480 - recall: 0.9473 - val_loss: 0.0903 - val_accuracy: 0.9644 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00064: val_accuracy improved from 0.96172 to 0.96436, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 65/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.1270 - accuracy: 0.9504 - recall: 0.9496 - val_loss: 0.1023 - val_accuracy: 0.9626 - val_recall: 0.9626\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.96436\n",
      "Epoch 66/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1205 - accuracy: 0.9564 - recall: 0.9557 - val_loss: 0.0921 - val_accuracy: 0.9613 - val_recall: 0.9608\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.96436\n",
      "Epoch 67/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1178 - accuracy: 0.9584 - recall: 0.9567 - val_loss: 0.0965 - val_accuracy: 0.9613 - val_recall: 0.9608\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.96436\n",
      "Epoch 68/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1255 - accuracy: 0.9525 - recall: 0.9524 - val_loss: 0.0944 - val_accuracy: 0.9617 - val_recall: 0.9613\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.96436\n",
      "Epoch 69/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1318 - accuracy: 0.9492 - recall: 0.9485 - val_loss: 0.0939 - val_accuracy: 0.9666 - val_recall: 0.9666\n",
      "\n",
      "Epoch 00069: val_accuracy improved from 0.96436 to 0.96656, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 70/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1184 - accuracy: 0.9551 - recall: 0.9547 - val_loss: 0.0894 - val_accuracy: 0.9635 - val_recall: 0.9626\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.96656\n",
      "Epoch 71/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1185 - accuracy: 0.9581 - recall: 0.9575 - val_loss: 0.0987 - val_accuracy: 0.9578 - val_recall: 0.9578\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.96656\n",
      "Epoch 72/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1157 - accuracy: 0.9578 - recall: 0.9573 - val_loss: 0.0955 - val_accuracy: 0.9622 - val_recall: 0.9617\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.96656\n",
      "Epoch 73/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1178 - accuracy: 0.9585 - recall: 0.9582 - val_loss: 0.1083 - val_accuracy: 0.9573 - val_recall: 0.9573\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.96656\n",
      "Epoch 74/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1140 - accuracy: 0.9588 - recall: 0.9583 - val_loss: 0.1159 - val_accuracy: 0.9520 - val_recall: 0.9503\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.96656\n",
      "Epoch 75/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1102 - accuracy: 0.9613 - recall: 0.9607 - val_loss: 0.0876 - val_accuracy: 0.9639 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.96656\n",
      "Epoch 76/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1178 - accuracy: 0.9583 - recall: 0.9574 - val_loss: 0.1333 - val_accuracy: 0.9463 - val_recall: 0.9450\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.96656\n",
      "Epoch 77/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1157 - accuracy: 0.9581 - recall: 0.9578 - val_loss: 0.0917 - val_accuracy: 0.9639 - val_recall: 0.9635\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.96656\n",
      "Epoch 78/400\n",
      "331/331 [==============================] - 42s 125ms/step - loss: 0.1158 - accuracy: 0.9578 - recall: 0.9573 - val_loss: 0.0956 - val_accuracy: 0.9604 - val_recall: 0.9604\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.96656\n",
      "Epoch 79/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1103 - accuracy: 0.9620 - recall: 0.9619 - val_loss: 0.1052 - val_accuracy: 0.9573 - val_recall: 0.9573\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.96656\n",
      "Epoch 80/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1133 - accuracy: 0.9578 - recall: 0.9575 - val_loss: 0.0812 - val_accuracy: 0.9688 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00080: val_accuracy improved from 0.96656 to 0.96876, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 81/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1182 - accuracy: 0.9572 - recall: 0.9568 - val_loss: 0.1352 - val_accuracy: 0.9516 - val_recall: 0.9512\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.96876\n",
      "Epoch 82/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1100 - accuracy: 0.9592 - recall: 0.9584 - val_loss: 0.0802 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.96876\n",
      "Epoch 83/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1081 - accuracy: 0.9592 - recall: 0.9584 - val_loss: 0.0950 - val_accuracy: 0.9635 - val_recall: 0.9622\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.96876\n",
      "Epoch 84/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.1096 - accuracy: 0.9584 - recall: 0.9583 - val_loss: 0.1051 - val_accuracy: 0.9586 - val_recall: 0.9582\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.96876\n",
      "Epoch 85/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.1084 - accuracy: 0.9617 - recall: 0.9615 - val_loss: 0.1005 - val_accuracy: 0.9600 - val_recall: 0.9595\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.96876\n",
      "Epoch 86/400\n",
      "331/331 [==============================] - 41s 122ms/step - loss: 0.1024 - accuracy: 0.9639 - recall: 0.9627 - val_loss: 0.0867 - val_accuracy: 0.9648 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.96876\n",
      "Epoch 87/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1101 - accuracy: 0.9601 - recall: 0.9595 - val_loss: 0.1008 - val_accuracy: 0.9564 - val_recall: 0.9556\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.96876\n",
      "Epoch 88/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1039 - accuracy: 0.9605 - recall: 0.9601 - val_loss: 0.0935 - val_accuracy: 0.9652 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.96876\n",
      "Epoch 89/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1063 - accuracy: 0.9620 - recall: 0.9618 - val_loss: 0.0837 - val_accuracy: 0.9657 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.96876\n",
      "Epoch 90/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1054 - accuracy: 0.9616 - recall: 0.9608 - val_loss: 0.0809 - val_accuracy: 0.9683 - val_recall: 0.9670\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.96876\n",
      "Epoch 91/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1075 - accuracy: 0.9609 - recall: 0.9601 - val_loss: 0.0948 - val_accuracy: 0.9630 - val_recall: 0.9622\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.96876\n",
      "Epoch 92/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0961 - accuracy: 0.9622 - recall: 0.9616 - val_loss: 0.0863 - val_accuracy: 0.9679 - val_recall: 0.9670\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.96876\n",
      "Epoch 93/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1032 - accuracy: 0.9655 - recall: 0.9650 - val_loss: 0.1202 - val_accuracy: 0.9516 - val_recall: 0.9512\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.96876\n",
      "Epoch 94/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.1017 - accuracy: 0.9623 - recall: 0.9622 - val_loss: 0.1214 - val_accuracy: 0.9556 - val_recall: 0.9551\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.96876\n",
      "Epoch 95/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0938 - accuracy: 0.9651 - recall: 0.9648 - val_loss: 0.0803 - val_accuracy: 0.9688 - val_recall: 0.9679\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.96876\n",
      "Epoch 96/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0888 - accuracy: 0.9660 - recall: 0.9644 - val_loss: 0.0887 - val_accuracy: 0.9661 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.96876\n",
      "Epoch 97/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0940 - accuracy: 0.9678 - recall: 0.9676 - val_loss: 0.0860 - val_accuracy: 0.9661 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.96876\n",
      "Epoch 98/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0918 - accuracy: 0.9683 - recall: 0.9679 - val_loss: 0.0831 - val_accuracy: 0.9644 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.96876\n",
      "Epoch 99/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0990 - accuracy: 0.9628 - recall: 0.9625 - val_loss: 0.1034 - val_accuracy: 0.9591 - val_recall: 0.9586\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.96876\n",
      "Epoch 100/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0891 - accuracy: 0.9652 - recall: 0.9648 - val_loss: 0.1207 - val_accuracy: 0.9498 - val_recall: 0.9498\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.96876\n",
      "Epoch 101/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0940 - accuracy: 0.9646 - recall: 0.9643 - val_loss: 0.1298 - val_accuracy: 0.9551 - val_recall: 0.9547\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.96876\n",
      "Epoch 102/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0880 - accuracy: 0.9690 - recall: 0.9687 - val_loss: 0.0936 - val_accuracy: 0.9613 - val_recall: 0.9608\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.96876\n",
      "Epoch 103/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0957 - accuracy: 0.9641 - recall: 0.9635 - val_loss: 0.0797 - val_accuracy: 0.9679 - val_recall: 0.9679\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.96876\n",
      "Epoch 104/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0946 - accuracy: 0.9653 - recall: 0.9648 - val_loss: 0.0838 - val_accuracy: 0.9679 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.96876\n",
      "Epoch 105/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0928 - accuracy: 0.9649 - recall: 0.9646 - val_loss: 0.1014 - val_accuracy: 0.9573 - val_recall: 0.9569\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.96876\n",
      "Epoch 106/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0890 - accuracy: 0.9690 - recall: 0.9680 - val_loss: 0.0785 - val_accuracy: 0.9714 - val_recall: 0.9714\n",
      "\n",
      "Epoch 00106: val_accuracy improved from 0.96876 to 0.97140, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 107/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0826 - accuracy: 0.9694 - recall: 0.9688 - val_loss: 0.0820 - val_accuracy: 0.9683 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.97140\n",
      "Epoch 108/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0859 - accuracy: 0.9699 - recall: 0.9696 - val_loss: 0.0790 - val_accuracy: 0.9683 - val_recall: 0.9679\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.97140\n",
      "Epoch 109/400\n",
      "331/331 [==============================] - 40s 122ms/step - loss: 0.0951 - accuracy: 0.9659 - recall: 0.9655 - val_loss: 0.0765 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.97140\n",
      "Epoch 110/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0906 - accuracy: 0.9689 - recall: 0.9686 - val_loss: 0.0843 - val_accuracy: 0.9652 - val_recall: 0.9652\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.97140\n",
      "Epoch 111/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0871 - accuracy: 0.9662 - recall: 0.9659 - val_loss: 0.0933 - val_accuracy: 0.9648 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.97140\n",
      "Epoch 112/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0842 - accuracy: 0.9668 - recall: 0.9665 - val_loss: 0.0811 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.97140\n",
      "Epoch 113/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0850 - accuracy: 0.9698 - recall: 0.9695 - val_loss: 0.0838 - val_accuracy: 0.9705 - val_recall: 0.9705\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.97140\n",
      "Epoch 114/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0907 - accuracy: 0.9664 - recall: 0.9661 - val_loss: 0.0831 - val_accuracy: 0.9661 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.97140\n",
      "Epoch 115/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0873 - accuracy: 0.9685 - recall: 0.9682 - val_loss: 0.0780 - val_accuracy: 0.9692 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.97140\n",
      "Epoch 116/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0846 - accuracy: 0.9690 - recall: 0.9687 - val_loss: 0.0834 - val_accuracy: 0.9661 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.97140\n",
      "Epoch 117/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0724 - accuracy: 0.9716 - recall: 0.9713 - val_loss: 0.0788 - val_accuracy: 0.9674 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.97140\n",
      "Epoch 118/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0756 - accuracy: 0.9743 - recall: 0.9738 - val_loss: 0.0989 - val_accuracy: 0.9617 - val_recall: 0.9617\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.97140\n",
      "Epoch 119/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0877 - accuracy: 0.9676 - recall: 0.9672 - val_loss: 0.0798 - val_accuracy: 0.9705 - val_recall: 0.9701\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.97140\n",
      "Epoch 120/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0767 - accuracy: 0.9718 - recall: 0.9718 - val_loss: 0.0973 - val_accuracy: 0.9604 - val_recall: 0.9604\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.97140\n",
      "Epoch 121/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0884 - accuracy: 0.9690 - recall: 0.9688 - val_loss: 0.1204 - val_accuracy: 0.9512 - val_recall: 0.9507\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.97140\n",
      "Epoch 122/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0783 - accuracy: 0.9717 - recall: 0.9715 - val_loss: 0.1033 - val_accuracy: 0.9613 - val_recall: 0.9608\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.97140\n",
      "Epoch 123/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0852 - accuracy: 0.9696 - recall: 0.9694 - val_loss: 0.0962 - val_accuracy: 0.9639 - val_recall: 0.9635\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.97140\n",
      "Epoch 124/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0880 - accuracy: 0.9687 - recall: 0.9686 - val_loss: 0.0716 - val_accuracy: 0.9740 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00124: val_accuracy improved from 0.97140 to 0.97404, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 125/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0814 - accuracy: 0.9726 - recall: 0.9723 - val_loss: 0.0916 - val_accuracy: 0.9639 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.97404\n",
      "Epoch 126/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0797 - accuracy: 0.9714 - recall: 0.9710 - val_loss: 0.0787 - val_accuracy: 0.9674 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.97404\n",
      "Epoch 127/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0902 - accuracy: 0.9686 - recall: 0.9677 - val_loss: 0.1088 - val_accuracy: 0.9608 - val_recall: 0.9608\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.97404\n",
      "Epoch 128/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0750 - accuracy: 0.9732 - recall: 0.9731 - val_loss: 0.0898 - val_accuracy: 0.9652 - val_recall: 0.9652\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.97404\n",
      "Epoch 129/400\n",
      "331/331 [==============================] - 40s 121ms/step - loss: 0.0783 - accuracy: 0.9744 - recall: 0.9744 - val_loss: 0.0940 - val_accuracy: 0.9630 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.97404\n",
      "Epoch 130/400\n",
      "331/331 [==============================] - 41s 124ms/step - loss: 0.0724 - accuracy: 0.9767 - recall: 0.9763 - val_loss: 0.1421 - val_accuracy: 0.9498 - val_recall: 0.9498\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.97404\n",
      "Epoch 131/400\n",
      "331/331 [==============================] - 41s 124ms/step - loss: 0.0688 - accuracy: 0.9760 - recall: 0.9751 - val_loss: 0.0788 - val_accuracy: 0.9701 - val_recall: 0.9701\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.97404\n",
      "Epoch 132/400\n",
      "331/331 [==============================] - 42s 125ms/step - loss: 0.0786 - accuracy: 0.9735 - recall: 0.9734 - val_loss: 0.0774 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.97404\n",
      "Epoch 133/400\n",
      "331/331 [==============================] - 41s 122ms/step - loss: 0.0825 - accuracy: 0.9668 - recall: 0.9663 - val_loss: 0.1156 - val_accuracy: 0.9569 - val_recall: 0.9569\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.97404\n",
      "Epoch 134/400\n",
      "331/331 [==============================] - 41s 123ms/step - loss: 0.0726 - accuracy: 0.9712 - recall: 0.9711 - val_loss: 0.0853 - val_accuracy: 0.9696 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.97404\n",
      "Epoch 135/400\n",
      "331/331 [==============================] - 41s 123ms/step - loss: 0.0793 - accuracy: 0.9715 - recall: 0.9715 - val_loss: 0.0878 - val_accuracy: 0.9666 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.97404\n",
      "Epoch 136/400\n",
      "331/331 [==============================] - 41s 122ms/step - loss: 0.0771 - accuracy: 0.9723 - recall: 0.9721 - val_loss: 0.0796 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.97404\n",
      "Epoch 137/400\n",
      "331/331 [==============================] - 41s 122ms/step - loss: 0.0807 - accuracy: 0.9722 - recall: 0.9718 - val_loss: 0.0945 - val_accuracy: 0.9630 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.97404\n",
      "Epoch 138/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0720 - accuracy: 0.9720 - recall: 0.9717 - val_loss: 0.0746 - val_accuracy: 0.9718 - val_recall: 0.9714\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.97404\n",
      "Epoch 139/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0753 - accuracy: 0.9736 - recall: 0.9732 - val_loss: 0.0746 - val_accuracy: 0.9740 - val_recall: 0.9740\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.97404\n",
      "Epoch 140/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0723 - accuracy: 0.9746 - recall: 0.9744 - val_loss: 0.0851 - val_accuracy: 0.9679 - val_recall: 0.9679\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.97404\n",
      "Epoch 141/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0598 - accuracy: 0.9780 - recall: 0.9780 - val_loss: 0.0815 - val_accuracy: 0.9696 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.97404\n",
      "Epoch 142/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0684 - accuracy: 0.9748 - recall: 0.9747 - val_loss: 0.1141 - val_accuracy: 0.9560 - val_recall: 0.9560\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.97404\n",
      "Epoch 143/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0727 - accuracy: 0.9725 - recall: 0.9721 - val_loss: 0.0782 - val_accuracy: 0.9714 - val_recall: 0.9710\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.97404\n",
      "Epoch 144/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0621 - accuracy: 0.9770 - recall: 0.9770 - val_loss: 0.0942 - val_accuracy: 0.9674 - val_recall: 0.9670\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.97404\n",
      "Epoch 145/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0649 - accuracy: 0.9752 - recall: 0.9750 - val_loss: 0.0782 - val_accuracy: 0.9692 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.97404\n",
      "Epoch 146/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0663 - accuracy: 0.9766 - recall: 0.9765 - val_loss: 0.0780 - val_accuracy: 0.9736 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.97404\n",
      "Epoch 147/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0681 - accuracy: 0.9732 - recall: 0.9730 - val_loss: 0.0860 - val_accuracy: 0.9692 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.97404\n",
      "Epoch 148/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0701 - accuracy: 0.9755 - recall: 0.9753 - val_loss: 0.0745 - val_accuracy: 0.9718 - val_recall: 0.9718\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.97404\n",
      "Epoch 149/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0686 - accuracy: 0.9736 - recall: 0.9735 - val_loss: 0.0708 - val_accuracy: 0.9749 - val_recall: 0.9749\n",
      "\n",
      "Epoch 00149: val_accuracy improved from 0.97404 to 0.97492, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 150/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0632 - accuracy: 0.9747 - recall: 0.9743 - val_loss: 0.0879 - val_accuracy: 0.9666 - val_recall: 0.9666\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.97492\n",
      "Epoch 151/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0732 - accuracy: 0.9732 - recall: 0.9732 - val_loss: 0.0866 - val_accuracy: 0.9701 - val_recall: 0.9701\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.97492\n",
      "Epoch 152/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0644 - accuracy: 0.9764 - recall: 0.9763 - val_loss: 0.0797 - val_accuracy: 0.9696 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.97492\n",
      "Epoch 153/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0649 - accuracy: 0.9760 - recall: 0.9758 - val_loss: 0.0711 - val_accuracy: 0.9736 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.97492\n",
      "Epoch 154/400\n",
      "331/331 [==============================] - 40s 122ms/step - loss: 0.0663 - accuracy: 0.9767 - recall: 0.9767 - val_loss: 0.0935 - val_accuracy: 0.9666 - val_recall: 0.9666\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.97492\n",
      "Epoch 155/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0597 - accuracy: 0.9764 - recall: 0.9762 - val_loss: 0.1472 - val_accuracy: 0.9498 - val_recall: 0.9490\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.97492\n",
      "Epoch 156/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0622 - accuracy: 0.9763 - recall: 0.9763 - val_loss: 0.0841 - val_accuracy: 0.9692 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.97492\n",
      "Epoch 157/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0680 - accuracy: 0.9749 - recall: 0.9747 - val_loss: 0.0840 - val_accuracy: 0.9710 - val_recall: 0.9701\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.97492\n",
      "Epoch 158/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0660 - accuracy: 0.9769 - recall: 0.9769 - val_loss: 0.1114 - val_accuracy: 0.9578 - val_recall: 0.9573\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.97492\n",
      "Epoch 159/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0650 - accuracy: 0.9765 - recall: 0.9762 - val_loss: 0.0870 - val_accuracy: 0.9666 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.97492\n",
      "Epoch 160/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0700 - accuracy: 0.9757 - recall: 0.9750 - val_loss: 0.2985 - val_accuracy: 0.9010 - val_recall: 0.9010\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.97492\n",
      "Epoch 161/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0673 - accuracy: 0.9753 - recall: 0.9750 - val_loss: 0.0950 - val_accuracy: 0.9692 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.97492\n",
      "Epoch 162/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0564 - accuracy: 0.9786 - recall: 0.9786 - val_loss: 0.0766 - val_accuracy: 0.9718 - val_recall: 0.9718\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.97492\n",
      "Epoch 163/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0615 - accuracy: 0.9771 - recall: 0.9765 - val_loss: 0.0736 - val_accuracy: 0.9762 - val_recall: 0.9762\n",
      "\n",
      "Epoch 00163: val_accuracy improved from 0.97492 to 0.97624, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 164/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0587 - accuracy: 0.9810 - recall: 0.9805 - val_loss: 0.1032 - val_accuracy: 0.9648 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.97624\n",
      "Epoch 165/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0623 - accuracy: 0.9744 - recall: 0.9744 - val_loss: 0.0808 - val_accuracy: 0.9723 - val_recall: 0.9714\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.97624\n",
      "Epoch 166/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0573 - accuracy: 0.9789 - recall: 0.9789 - val_loss: 0.0977 - val_accuracy: 0.9644 - val_recall: 0.9635\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.97624\n",
      "Epoch 167/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0618 - accuracy: 0.9763 - recall: 0.9759 - val_loss: 0.0893 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.97624\n",
      "Epoch 168/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0598 - accuracy: 0.9775 - recall: 0.9773 - val_loss: 0.0799 - val_accuracy: 0.9723 - val_recall: 0.9723\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.97624\n",
      "Epoch 169/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0705 - accuracy: 0.9735 - recall: 0.9735 - val_loss: 0.1049 - val_accuracy: 0.9644 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.97624\n",
      "Epoch 170/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0635 - accuracy: 0.9751 - recall: 0.9748 - val_loss: 0.0871 - val_accuracy: 0.9683 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.97624\n",
      "Epoch 171/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0567 - accuracy: 0.9794 - recall: 0.9793 - val_loss: 0.0759 - val_accuracy: 0.9732 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.97624\n",
      "Epoch 172/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0540 - accuracy: 0.9810 - recall: 0.9809 - val_loss: 0.0681 - val_accuracy: 0.9745 - val_recall: 0.9745\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.97624\n",
      "Epoch 173/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0583 - accuracy: 0.9795 - recall: 0.9795 - val_loss: 0.0847 - val_accuracy: 0.9696 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.97624\n",
      "Epoch 174/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0590 - accuracy: 0.9778 - recall: 0.9776 - val_loss: 0.0908 - val_accuracy: 0.9692 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.97624\n",
      "Epoch 175/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0586 - accuracy: 0.9783 - recall: 0.9783 - val_loss: 0.0769 - val_accuracy: 0.9732 - val_recall: 0.9723\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.97624\n",
      "Epoch 176/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0529 - accuracy: 0.9814 - recall: 0.9814 - val_loss: 0.1224 - val_accuracy: 0.9573 - val_recall: 0.9569\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.97624\n",
      "Epoch 177/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0571 - accuracy: 0.9796 - recall: 0.9795 - val_loss: 0.0908 - val_accuracy: 0.9661 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.97624\n",
      "Epoch 178/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0532 - accuracy: 0.9790 - recall: 0.9789 - val_loss: 0.0938 - val_accuracy: 0.9692 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.97624\n",
      "Epoch 179/400\n",
      "331/331 [==============================] - 40s 121ms/step - loss: 0.0547 - accuracy: 0.9793 - recall: 0.9791 - val_loss: 0.0831 - val_accuracy: 0.9666 - val_recall: 0.9666\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.97624\n",
      "Epoch 180/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0526 - accuracy: 0.9808 - recall: 0.9808 - val_loss: 0.0832 - val_accuracy: 0.9696 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.97624\n",
      "Epoch 181/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0587 - accuracy: 0.9800 - recall: 0.9800 - val_loss: 0.0930 - val_accuracy: 0.9670 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.97624\n",
      "Epoch 182/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0523 - accuracy: 0.9833 - recall: 0.9828 - val_loss: 0.0877 - val_accuracy: 0.9736 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.97624\n",
      "Epoch 183/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0548 - accuracy: 0.9785 - recall: 0.9782 - val_loss: 0.0947 - val_accuracy: 0.9661 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.97624\n",
      "Epoch 184/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0571 - accuracy: 0.9804 - recall: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.97624\n",
      "Epoch 185/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0538 - accuracy: 0.9776 - recall: 0.9775 - val_loss: 0.0748 - val_accuracy: 0.9736 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.97624\n",
      "Epoch 186/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0564 - accuracy: 0.9807 - recall: 0.9807 - val_loss: 0.0900 - val_accuracy: 0.9674 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.97624\n",
      "Epoch 187/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0623 - accuracy: 0.9745 - recall: 0.9743 - val_loss: 0.0969 - val_accuracy: 0.9626 - val_recall: 0.9622\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.97624\n",
      "Epoch 188/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0593 - accuracy: 0.9796 - recall: 0.9796 - val_loss: 0.0817 - val_accuracy: 0.9740 - val_recall: 0.9740\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.97624\n",
      "Epoch 189/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0538 - accuracy: 0.9800 - recall: 0.9799 - val_loss: 0.0736 - val_accuracy: 0.9780 - val_recall: 0.9780\n",
      "\n",
      "Epoch 00189: val_accuracy improved from 0.97624 to 0.97800, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 190/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0503 - accuracy: 0.9811 - recall: 0.9809 - val_loss: 0.0993 - val_accuracy: 0.9657 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.97800\n",
      "Epoch 191/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0485 - accuracy: 0.9837 - recall: 0.9833 - val_loss: 0.0771 - val_accuracy: 0.9723 - val_recall: 0.9723\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.97800\n",
      "Epoch 192/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0566 - accuracy: 0.9799 - recall: 0.9798 - val_loss: 0.1048 - val_accuracy: 0.9626 - val_recall: 0.9626\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.97800\n",
      "Epoch 193/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0522 - accuracy: 0.9828 - recall: 0.9822 - val_loss: 0.1115 - val_accuracy: 0.9595 - val_recall: 0.9586\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.97800\n",
      "Epoch 194/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0499 - accuracy: 0.9833 - recall: 0.9833 - val_loss: 0.0767 - val_accuracy: 0.9740 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.97800\n",
      "Epoch 195/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0560 - accuracy: 0.9800 - recall: 0.9799 - val_loss: 0.0793 - val_accuracy: 0.9727 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.97800\n",
      "Epoch 196/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0556 - accuracy: 0.9789 - recall: 0.9787 - val_loss: 0.1056 - val_accuracy: 0.9661 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.97800\n",
      "Epoch 197/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0520 - accuracy: 0.9814 - recall: 0.9812 - val_loss: 0.1052 - val_accuracy: 0.9648 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.97800\n",
      "Epoch 198/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0518 - accuracy: 0.9809 - recall: 0.9804 - val_loss: 0.1438 - val_accuracy: 0.9538 - val_recall: 0.9538\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.97800\n",
      "Epoch 199/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0489 - accuracy: 0.9812 - recall: 0.9812 - val_loss: 0.0911 - val_accuracy: 0.9701 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.97800\n",
      "Epoch 200/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0530 - accuracy: 0.9803 - recall: 0.9794 - val_loss: 0.0876 - val_accuracy: 0.9705 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.97800\n",
      "Epoch 201/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0540 - accuracy: 0.9799 - recall: 0.9798 - val_loss: 0.1868 - val_accuracy: 0.9362 - val_recall: 0.9362\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.97800\n",
      "Epoch 202/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0538 - accuracy: 0.9789 - recall: 0.9787 - val_loss: 0.0818 - val_accuracy: 0.9732 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.97800\n",
      "Epoch 203/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0508 - accuracy: 0.9823 - recall: 0.9819 - val_loss: 0.0866 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.97800\n",
      "Epoch 204/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0506 - accuracy: 0.9816 - recall: 0.9816 - val_loss: 0.0896 - val_accuracy: 0.9696 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.97800\n",
      "Epoch 205/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0493 - accuracy: 0.9814 - recall: 0.9814 - val_loss: 0.1013 - val_accuracy: 0.9666 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.97800\n",
      "Epoch 206/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0458 - accuracy: 0.9840 - recall: 0.9833 - val_loss: 0.0929 - val_accuracy: 0.9657 - val_recall: 0.9652\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.97800\n",
      "Epoch 207/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0504 - accuracy: 0.9815 - recall: 0.9814 - val_loss: 0.0864 - val_accuracy: 0.9648 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.97800\n",
      "Epoch 208/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0440 - accuracy: 0.9841 - recall: 0.9840 - val_loss: 0.0762 - val_accuracy: 0.9727 - val_recall: 0.9723\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.97800\n",
      "Epoch 209/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0470 - accuracy: 0.9815 - recall: 0.9815 - val_loss: 0.0745 - val_accuracy: 0.9727 - val_recall: 0.9723\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.97800\n",
      "Epoch 210/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0523 - accuracy: 0.9823 - recall: 0.9820 - val_loss: 0.0686 - val_accuracy: 0.9732 - val_recall: 0.9732\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.97800\n",
      "Epoch 211/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0469 - accuracy: 0.9844 - recall: 0.9844 - val_loss: 0.0967 - val_accuracy: 0.9657 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.97800\n",
      "Epoch 212/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0512 - accuracy: 0.9813 - recall: 0.9812 - val_loss: 0.0748 - val_accuracy: 0.9758 - val_recall: 0.9758\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.97800\n",
      "Epoch 213/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0500 - accuracy: 0.9809 - recall: 0.9808 - val_loss: 0.0974 - val_accuracy: 0.9648 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.97800\n",
      "Epoch 214/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0492 - accuracy: 0.9812 - recall: 0.9811 - val_loss: 0.0712 - val_accuracy: 0.9749 - val_recall: 0.9745\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.97800\n",
      "Epoch 215/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0435 - accuracy: 0.9858 - recall: 0.9858 - val_loss: 0.0754 - val_accuracy: 0.9714 - val_recall: 0.9714\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.97800\n",
      "Epoch 216/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0440 - accuracy: 0.9835 - recall: 0.9835 - val_loss: 0.0914 - val_accuracy: 0.9705 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.97800\n",
      "Epoch 217/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0470 - accuracy: 0.9852 - recall: 0.9846 - val_loss: 0.0705 - val_accuracy: 0.9749 - val_recall: 0.9749\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.97800\n",
      "Epoch 218/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0448 - accuracy: 0.9818 - recall: 0.9818 - val_loss: 0.0996 - val_accuracy: 0.9692 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.97800\n",
      "Epoch 219/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0481 - accuracy: 0.9812 - recall: 0.9809 - val_loss: 0.0825 - val_accuracy: 0.9718 - val_recall: 0.9718\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.97800\n",
      "Epoch 220/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0405 - accuracy: 0.9868 - recall: 0.9867 - val_loss: 0.1196 - val_accuracy: 0.9617 - val_recall: 0.9617\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.97800\n",
      "Epoch 221/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0456 - accuracy: 0.9830 - recall: 0.9830 - val_loss: 0.0770 - val_accuracy: 0.9749 - val_recall: 0.9749\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.97800\n",
      "Epoch 222/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0440 - accuracy: 0.9836 - recall: 0.9836 - val_loss: 0.1010 - val_accuracy: 0.9639 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.97800\n",
      "Epoch 223/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0405 - accuracy: 0.9843 - recall: 0.9840 - val_loss: 0.0807 - val_accuracy: 0.9718 - val_recall: 0.9718\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.97800\n",
      "Epoch 224/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0477 - accuracy: 0.9837 - recall: 0.9837 - val_loss: 0.1259 - val_accuracy: 0.9582 - val_recall: 0.9578\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.97800\n",
      "Epoch 225/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0480 - accuracy: 0.9830 - recall: 0.9830 - val_loss: 0.1279 - val_accuracy: 0.9542 - val_recall: 0.9542\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.97800\n",
      "Epoch 226/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0461 - accuracy: 0.9833 - recall: 0.9832 - val_loss: 0.1250 - val_accuracy: 0.9573 - val_recall: 0.9573\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.97800\n",
      "Epoch 227/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0447 - accuracy: 0.9843 - recall: 0.9839 - val_loss: 0.0897 - val_accuracy: 0.9679 - val_recall: 0.9679\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.97800\n",
      "Epoch 228/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0480 - accuracy: 0.9808 - recall: 0.9806 - val_loss: 0.0767 - val_accuracy: 0.9727 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.97800\n",
      "Epoch 229/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0429 - accuracy: 0.9844 - recall: 0.9841 - val_loss: 0.0755 - val_accuracy: 0.9736 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.97800\n",
      "Epoch 230/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0437 - accuracy: 0.9831 - recall: 0.9831 - val_loss: 0.0849 - val_accuracy: 0.9710 - val_recall: 0.9710\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.97800\n",
      "Epoch 231/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0411 - accuracy: 0.9854 - recall: 0.9851 - val_loss: 0.0866 - val_accuracy: 0.9696 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.97800\n",
      "Epoch 232/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0503 - accuracy: 0.9809 - recall: 0.9809 - val_loss: 0.0849 - val_accuracy: 0.9696 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.97800\n",
      "Epoch 233/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0407 - accuracy: 0.9841 - recall: 0.9840 - val_loss: 0.0765 - val_accuracy: 0.9740 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.97800\n",
      "Epoch 234/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0436 - accuracy: 0.9832 - recall: 0.9831 - val_loss: 0.0788 - val_accuracy: 0.9701 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.97800\n",
      "Epoch 235/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0469 - accuracy: 0.9834 - recall: 0.9834 - val_loss: 0.0908 - val_accuracy: 0.9688 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.97800\n",
      "Epoch 236/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0429 - accuracy: 0.9839 - recall: 0.9839 - val_loss: 0.0929 - val_accuracy: 0.9679 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.97800\n",
      "Epoch 237/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0362 - accuracy: 0.9870 - recall: 0.9868 - val_loss: 0.0881 - val_accuracy: 0.9683 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.97800\n",
      "Epoch 238/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0388 - accuracy: 0.9845 - recall: 0.9842 - val_loss: 0.1009 - val_accuracy: 0.9692 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.97800\n",
      "Epoch 239/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0416 - accuracy: 0.9857 - recall: 0.9855 - val_loss: 0.1007 - val_accuracy: 0.9696 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.97800\n",
      "Epoch 240/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0438 - accuracy: 0.9821 - recall: 0.9821 - val_loss: 0.0923 - val_accuracy: 0.9683 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.97800\n",
      "Epoch 241/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0407 - accuracy: 0.9866 - recall: 0.9865 - val_loss: 0.0623 - val_accuracy: 0.9820 - val_recall: 0.9820\n",
      "\n",
      "Epoch 00241: val_accuracy improved from 0.97800 to 0.98196, saving model to /home/hivini/learn/research/new-covid/best_model.h5\n",
      "Epoch 242/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0452 - accuracy: 0.9825 - recall: 0.9821 - val_loss: 0.0999 - val_accuracy: 0.9666 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.98196\n",
      "Epoch 243/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0443 - accuracy: 0.9841 - recall: 0.9838 - val_loss: 0.1067 - val_accuracy: 0.9648 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.98196\n",
      "Epoch 244/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0427 - accuracy: 0.9844 - recall: 0.9844 - val_loss: 0.1324 - val_accuracy: 0.9560 - val_recall: 0.9560\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.98196\n",
      "Epoch 245/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0449 - accuracy: 0.9827 - recall: 0.9824 - val_loss: 0.0974 - val_accuracy: 0.9683 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.98196\n",
      "Epoch 246/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0358 - accuracy: 0.9871 - recall: 0.9870 - val_loss: 0.1039 - val_accuracy: 0.9657 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.98196\n",
      "Epoch 247/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0397 - accuracy: 0.9846 - recall: 0.9846 - val_loss: 0.0779 - val_accuracy: 0.9762 - val_recall: 0.9762\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.98196\n",
      "Epoch 248/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0418 - accuracy: 0.9861 - recall: 0.9858 - val_loss: 0.0912 - val_accuracy: 0.9674 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.98196\n",
      "Epoch 249/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0357 - accuracy: 0.9874 - recall: 0.9871 - val_loss: 0.0772 - val_accuracy: 0.9749 - val_recall: 0.9749\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.98196\n",
      "Epoch 250/400\n",
      "331/331 [==============================] - 39s 118ms/step - loss: 0.0398 - accuracy: 0.9838 - recall: 0.9832 - val_loss: 0.1265 - val_accuracy: 0.9600 - val_recall: 0.9600\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.98196\n",
      "Epoch 251/400\n",
      "331/331 [==============================] - 39s 117ms/step - loss: 0.0360 - accuracy: 0.9873 - recall: 0.9868 - val_loss: 0.1071 - val_accuracy: 0.9661 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.98196\n",
      "Epoch 252/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0339 - accuracy: 0.9892 - recall: 0.9891 - val_loss: 0.0811 - val_accuracy: 0.9767 - val_recall: 0.9767\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.98196\n",
      "Epoch 253/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0394 - accuracy: 0.9856 - recall: 0.9855 - val_loss: 0.0972 - val_accuracy: 0.9692 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.98196\n",
      "Epoch 254/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0434 - accuracy: 0.9860 - recall: 0.9858 - val_loss: 0.1092 - val_accuracy: 0.9661 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.98196\n",
      "Epoch 255/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0411 - accuracy: 0.9839 - recall: 0.9838 - val_loss: 0.0799 - val_accuracy: 0.9732 - val_recall: 0.9732\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.98196\n",
      "Epoch 256/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0375 - accuracy: 0.9859 - recall: 0.9858 - val_loss: 0.0916 - val_accuracy: 0.9666 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.98196\n",
      "Epoch 257/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0421 - accuracy: 0.9841 - recall: 0.9841 - val_loss: 0.0725 - val_accuracy: 0.9758 - val_recall: 0.9758\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.98196\n",
      "Epoch 258/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0334 - accuracy: 0.9875 - recall: 0.9874 - val_loss: 0.1048 - val_accuracy: 0.9683 - val_recall: 0.9679\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.98196\n",
      "Epoch 259/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0351 - accuracy: 0.9862 - recall: 0.9862 - val_loss: 0.0863 - val_accuracy: 0.9696 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.98196\n",
      "Epoch 260/400\n",
      "331/331 [==============================] - 40s 122ms/step - loss: 0.0385 - accuracy: 0.9866 - recall: 0.9865 - val_loss: 0.0741 - val_accuracy: 0.9740 - val_recall: 0.9740\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.98196\n",
      "Epoch 261/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0425 - accuracy: 0.9852 - recall: 0.9851 - val_loss: 0.1113 - val_accuracy: 0.9617 - val_recall: 0.9617\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.98196\n",
      "Epoch 262/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0386 - accuracy: 0.9850 - recall: 0.9847 - val_loss: 0.0768 - val_accuracy: 0.9749 - val_recall: 0.9749\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.98196\n",
      "Epoch 263/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0342 - accuracy: 0.9870 - recall: 0.9870 - val_loss: 0.0846 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.98196\n",
      "Epoch 264/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0353 - accuracy: 0.9874 - recall: 0.9874 - val_loss: 0.0799 - val_accuracy: 0.9732 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.98196\n",
      "Epoch 265/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0412 - accuracy: 0.9852 - recall: 0.9850 - val_loss: 0.1809 - val_accuracy: 0.9406 - val_recall: 0.9402\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.98196\n",
      "Epoch 266/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0384 - accuracy: 0.9848 - recall: 0.9847 - val_loss: 0.2902 - val_accuracy: 0.9239 - val_recall: 0.9234\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.98196\n",
      "Epoch 267/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0377 - accuracy: 0.9863 - recall: 0.9860 - val_loss: 0.0772 - val_accuracy: 0.9727 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.98196\n",
      "Epoch 268/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0447 - accuracy: 0.9838 - recall: 0.9836 - val_loss: 0.0779 - val_accuracy: 0.9736 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.98196\n",
      "Epoch 269/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0402 - accuracy: 0.9855 - recall: 0.9855 - val_loss: 0.0825 - val_accuracy: 0.9732 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.98196\n",
      "Epoch 270/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0387 - accuracy: 0.9856 - recall: 0.9855 - val_loss: 0.1163 - val_accuracy: 0.9666 - val_recall: 0.9666\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.98196\n",
      "Epoch 271/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0375 - accuracy: 0.9864 - recall: 0.9862 - val_loss: 0.0755 - val_accuracy: 0.9749 - val_recall: 0.9745\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.98196\n",
      "Epoch 272/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0353 - accuracy: 0.9882 - recall: 0.9881 - val_loss: 0.0811 - val_accuracy: 0.9736 - val_recall: 0.9732\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.98196\n",
      "Epoch 273/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0374 - accuracy: 0.9863 - recall: 0.9862 - val_loss: 0.0846 - val_accuracy: 0.9710 - val_recall: 0.9705\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.98196\n",
      "Epoch 274/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0320 - accuracy: 0.9887 - recall: 0.9887 - val_loss: 0.1058 - val_accuracy: 0.9648 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.98196\n",
      "Epoch 275/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0321 - accuracy: 0.9873 - recall: 0.9873 - val_loss: 0.0824 - val_accuracy: 0.9723 - val_recall: 0.9723\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.98196\n",
      "Epoch 276/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0395 - accuracy: 0.9856 - recall: 0.9853 - val_loss: 0.1945 - val_accuracy: 0.9384 - val_recall: 0.9384\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.98196\n",
      "Epoch 277/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0378 - accuracy: 0.9875 - recall: 0.9874 - val_loss: 0.1216 - val_accuracy: 0.9626 - val_recall: 0.9622\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.98196\n",
      "Epoch 278/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0351 - accuracy: 0.9884 - recall: 0.9883 - val_loss: 0.0738 - val_accuracy: 0.9754 - val_recall: 0.9754\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.98196\n",
      "Epoch 279/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0312 - accuracy: 0.9891 - recall: 0.9891 - val_loss: 0.1409 - val_accuracy: 0.9547 - val_recall: 0.9547\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.98196\n",
      "Epoch 280/400\n",
      "331/331 [==============================] - 40s 119ms/step - loss: 0.0376 - accuracy: 0.9864 - recall: 0.9864 - val_loss: 0.0713 - val_accuracy: 0.9776 - val_recall: 0.9771\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.98196\n",
      "Epoch 281/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0321 - accuracy: 0.9879 - recall: 0.9879 - val_loss: 0.1250 - val_accuracy: 0.9608 - val_recall: 0.9608\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.98196\n",
      "Epoch 282/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0305 - accuracy: 0.9892 - recall: 0.9892 - val_loss: 0.0765 - val_accuracy: 0.9740 - val_recall: 0.9736\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.98196\n",
      "Epoch 283/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0334 - accuracy: 0.9866 - recall: 0.9865 - val_loss: 0.0768 - val_accuracy: 0.9745 - val_recall: 0.9745\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.98196\n",
      "Epoch 284/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0437 - accuracy: 0.9839 - recall: 0.9838 - val_loss: 0.1936 - val_accuracy: 0.9384 - val_recall: 0.9380\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.98196\n",
      "Epoch 285/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0356 - accuracy: 0.9879 - recall: 0.9877 - val_loss: 0.1153 - val_accuracy: 0.9639 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.98196\n",
      "Epoch 286/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0347 - accuracy: 0.9858 - recall: 0.9858 - val_loss: 0.1282 - val_accuracy: 0.9538 - val_recall: 0.9538\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.98196\n",
      "Epoch 287/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0337 - accuracy: 0.9885 - recall: 0.9885 - val_loss: 0.1199 - val_accuracy: 0.9652 - val_recall: 0.9652\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.98196\n",
      "Epoch 288/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0358 - accuracy: 0.9877 - recall: 0.9877 - val_loss: 0.1218 - val_accuracy: 0.9613 - val_recall: 0.9604\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.98196\n",
      "Epoch 289/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0327 - accuracy: 0.9887 - recall: 0.9887 - val_loss: 0.1149 - val_accuracy: 0.9622 - val_recall: 0.9622\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.98196\n",
      "Epoch 290/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0306 - accuracy: 0.9895 - recall: 0.9895 - val_loss: 0.0879 - val_accuracy: 0.9710 - val_recall: 0.9710\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.98196\n",
      "Epoch 291/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0330 - accuracy: 0.9891 - recall: 0.9891 - val_loss: 0.0677 - val_accuracy: 0.9758 - val_recall: 0.9758\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.98196\n",
      "Epoch 292/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0285 - accuracy: 0.9889 - recall: 0.9889 - val_loss: 0.1106 - val_accuracy: 0.9630 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.98196\n",
      "Epoch 293/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0348 - accuracy: 0.9868 - recall: 0.9865 - val_loss: 0.0905 - val_accuracy: 0.9705 - val_recall: 0.9705\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.98196\n",
      "Epoch 294/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0327 - accuracy: 0.9860 - recall: 0.9860 - val_loss: 0.0863 - val_accuracy: 0.9696 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.98196\n",
      "Epoch 295/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0351 - accuracy: 0.9840 - recall: 0.9840 - val_loss: 0.0693 - val_accuracy: 0.9754 - val_recall: 0.9754\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.98196\n",
      "Epoch 296/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0363 - accuracy: 0.9874 - recall: 0.9873 - val_loss: 0.0844 - val_accuracy: 0.9688 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.98196\n",
      "Epoch 297/400\n",
      "331/331 [==============================] - 39s 119ms/step - loss: 0.0289 - accuracy: 0.9899 - recall: 0.9895 - val_loss: 0.1034 - val_accuracy: 0.9644 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.98196\n",
      "Epoch 298/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0300 - accuracy: 0.9889 - recall: 0.9889 - val_loss: 0.0702 - val_accuracy: 0.9776 - val_recall: 0.9771\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.98196\n",
      "Epoch 299/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0329 - accuracy: 0.9895 - recall: 0.9894 - val_loss: 0.0803 - val_accuracy: 0.9718 - val_recall: 0.9718\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.98196\n",
      "Epoch 300/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0324 - accuracy: 0.9892 - recall: 0.9891 - val_loss: 0.0844 - val_accuracy: 0.9692 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.98196\n",
      "Epoch 301/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0344 - accuracy: 0.9871 - recall: 0.9870 - val_loss: 0.0942 - val_accuracy: 0.9688 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.98196\n",
      "Epoch 302/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0351 - accuracy: 0.9871 - recall: 0.9871 - val_loss: 0.1076 - val_accuracy: 0.9701 - val_recall: 0.9696\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.98196\n",
      "Epoch 303/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0312 - accuracy: 0.9873 - recall: 0.9871 - val_loss: 0.0979 - val_accuracy: 0.9674 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.98196\n",
      "Epoch 304/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0348 - accuracy: 0.9887 - recall: 0.9885 - val_loss: 0.1080 - val_accuracy: 0.9670 - val_recall: 0.9670\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.98196\n",
      "Epoch 305/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0360 - accuracy: 0.9876 - recall: 0.9874 - val_loss: 0.0957 - val_accuracy: 0.9710 - val_recall: 0.9710\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.98196\n",
      "Epoch 306/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0349 - accuracy: 0.9859 - recall: 0.9859 - val_loss: 0.0945 - val_accuracy: 0.9683 - val_recall: 0.9683\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.98196\n",
      "Epoch 307/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0333 - accuracy: 0.9879 - recall: 0.9879 - val_loss: 0.1132 - val_accuracy: 0.9692 - val_recall: 0.9692\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.98196\n",
      "Epoch 308/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0292 - accuracy: 0.9892 - recall: 0.9890 - val_loss: 0.0971 - val_accuracy: 0.9674 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.98196\n",
      "Epoch 309/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0288 - accuracy: 0.9889 - recall: 0.9886 - val_loss: 0.2822 - val_accuracy: 0.9173 - val_recall: 0.9173\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.98196\n",
      "Epoch 310/400\n",
      "331/331 [==============================] - 40s 122ms/step - loss: 0.0284 - accuracy: 0.9866 - recall: 0.9864 - val_loss: 0.1078 - val_accuracy: 0.9670 - val_recall: 0.9670\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.98196\n",
      "Epoch 311/400\n",
      "331/331 [==============================] - 45s 137ms/step - loss: 0.0352 - accuracy: 0.9885 - recall: 0.9884 - val_loss: 0.0956 - val_accuracy: 0.9692 - val_recall: 0.9688\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.98196\n",
      "Epoch 312/400\n",
      "331/331 [==============================] - 42s 126ms/step - loss: 0.0301 - accuracy: 0.9895 - recall: 0.9894 - val_loss: 0.1073 - val_accuracy: 0.9666 - val_recall: 0.9666\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.98196\n",
      "Epoch 313/400\n",
      "331/331 [==============================] - 42s 128ms/step - loss: 0.0337 - accuracy: 0.9880 - recall: 0.9880 - val_loss: 0.1180 - val_accuracy: 0.9626 - val_recall: 0.9626\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.98196\n",
      "Epoch 314/400\n",
      "331/331 [==============================] - 44s 133ms/step - loss: 0.0342 - accuracy: 0.9873 - recall: 0.9873 - val_loss: 0.0758 - val_accuracy: 0.9771 - val_recall: 0.9771\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.98196\n",
      "Epoch 315/400\n",
      "331/331 [==============================] - 40s 121ms/step - loss: 0.0272 - accuracy: 0.9909 - recall: 0.9909 - val_loss: 0.0834 - val_accuracy: 0.9723 - val_recall: 0.9723\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.98196\n",
      "Epoch 316/400\n",
      "331/331 [==============================] - 41s 125ms/step - loss: 0.0340 - accuracy: 0.9885 - recall: 0.9885 - val_loss: 0.0818 - val_accuracy: 0.9727 - val_recall: 0.9727\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.98196\n",
      "Epoch 317/400\n",
      "331/331 [==============================] - 41s 123ms/step - loss: 0.0295 - accuracy: 0.9900 - recall: 0.9894 - val_loss: 0.1100 - val_accuracy: 0.9674 - val_recall: 0.9674\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.98196\n",
      "Epoch 318/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0323 - accuracy: 0.9884 - recall: 0.9884 - val_loss: 0.1662 - val_accuracy: 0.9481 - val_recall: 0.9476\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.98196\n",
      "Epoch 319/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0223 - accuracy: 0.9925 - recall: 0.9922 - val_loss: 0.1095 - val_accuracy: 0.9666 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.98196\n",
      "Epoch 320/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0325 - accuracy: 0.9885 - recall: 0.9884 - val_loss: 0.0812 - val_accuracy: 0.9758 - val_recall: 0.9758\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.98196\n",
      "Epoch 321/400\n",
      "331/331 [==============================] - 40s 120ms/step - loss: 0.0343 - accuracy: 0.9882 - recall: 0.9881 - val_loss: 0.0694 - val_accuracy: 0.9780 - val_recall: 0.9780\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.98196\n",
      "Epoch 00321: early stopping\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "classes = train_generator.classes\n",
    "class_weights = class_weight.compute_class_weight(None,\n",
    "                                                 np.unique(classes),\n",
    "                                                 classes)\n",
    "best_model_path = os.path.join(BASE_PATH, 'best_model.h5')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=80)\n",
    "mc = ModelCheckpoint(best_model_path, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // 32,\n",
    "    epochs=400,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=dict(zip(np.unique(classes), class_weights)),\n",
    "    callbacks=[es, mc]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(BASE_PATH, 'covid_classifier_result.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 12s 166ms/step - loss: 0.0862 - accuracy: 0.9763 - recall: 0.9758\n",
      "Loss on test set:  0.08618113398551941\n",
      "Accuracy on test set:  0.9762532711029053\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_recall = model.evaluate(test_generator)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "# bo is for blue dot.\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "# b is for solid blue line\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "732f00c41ec6febe1195a3ec4989d3211f40efb04fd77f25a6f0f8bfd6feb066"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
